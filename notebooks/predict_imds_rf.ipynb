{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Municipal Sustainable Development Index (IMDS) Using Satellite Embeddings\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/quarcs-lab/ds4bolivia/blob/master/notebooks/predict_imds_rf.ipynb)\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates how to predict the **IMDS (Índice Municipal de Desarrollo Sostenible)** - a composite index that aggregates all Sustainable Development Goal (SDG) indicators into a single municipal development score - using 64-dimensional satellite imagery embeddings from Google Earth Engine.\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1. Load and merge multiple datasets for machine learning\n",
    "2. Prepare features and target variables for regression\n",
    "3. Train a Random Forest model with cross-validation\n",
    "4. Evaluate model performance using appropriate metrics\n",
    "5. Analyze feature importance from satellite embeddings\n",
    "6. Interpret prediction errors and identify patterns\n",
    "\n",
    "### About the IMDS\n",
    "\n",
    "The IMDS provides a comprehensive measure of sustainable development at the municipal level in Bolivia. It combines indicators across all 17 SDGs into a single normalized score (0-100), making it valuable for:\n",
    "\n",
    "- Comparing overall development across municipalities\n",
    "- Tracking progress toward sustainable development\n",
    "- Identifying areas requiring targeted interventions\n",
    "\n",
    "### Research Question\n",
    "\n",
    "**Can satellite imagery features predict overall municipal sustainable development in Bolivia?**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Libraries\n",
    "\n",
    "First, we import all necessary libraries for data manipulation, machine learning, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "\n",
    "We load three datasets from the DS4Bolivia repository:\n",
    "\n",
    "1. **SDG Data**: Contains the IMDS (our target variable) and other SDG indices\n",
    "2. **Satellite Embeddings**: 64-dimensional feature vectors derived from Google Earth Engine\n",
    "3. **Region Names**: Municipality and department names for interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data URLs from the DS4Bolivia repository\n",
    "REPO_URL = \"https://raw.githubusercontent.com/quarcs-lab/ds4bolivia/master\"\n",
    "\n",
    "url_sdg = f\"{REPO_URL}/sdg/sdg.csv\"\n",
    "url_emb = f\"{REPO_URL}/satelliteEmbeddings/satelliteEmbeddings2017.csv\"\n",
    "url_names = f\"{REPO_URL}/regionNames/regionNames.csv\"\n",
    "\n",
    "# Load datasets\n",
    "print(\"Loading datasets...\")\n",
    "df_sdg = pd.read_csv(url_sdg)\n",
    "df_embeddings = pd.read_csv(url_emb)\n",
    "df_names = pd.read_csv(url_names)\n",
    "\n",
    "print(f\"SDG data loaded: {len(df_sdg)} municipalities\")\n",
    "print(f\"Satellite embeddings loaded: {len(df_embeddings)} municipalities\")\n",
    "print(f\"Region names loaded: {len(df_names)} municipalities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Explore the SDG Data\n",
    "\n",
    "Let's examine the structure of our SDG dataset and understand the IMDS variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display SDG dataset structure\n",
    "print(\"SDG Dataset Columns:\")\n",
    "print(df_sdg.columns.tolist())\n",
    "print(f\"\\nShape: {df_sdg.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the IMDS variable\n",
    "print(\"IMDS (Municipal Sustainable Development Index) Statistics:\")\n",
    "print(df_sdg['imds'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Explore the Satellite Embeddings\n",
    "\n",
    "The satellite embeddings are 64-dimensional vectors (A00 to A63) derived from satellite imagery using deep learning models in Google Earth Engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display embedding structure\n",
    "print(\"Satellite Embeddings Columns:\")\n",
    "print(df_embeddings.columns.tolist())\n",
    "print(f\"\\nShape: {df_embeddings.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df_embeddings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation\n",
    "\n",
    "We merge our datasets using `asdf_id` as the common identifier and prepare our features (X) and target variable (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge datasets\n",
    "# Step 1: Merge SDG data (with IMDS) with satellite embeddings\n",
    "df_merged = df_sdg[['asdf_id', 'imds']].merge(\n",
    "    df_embeddings,\n",
    "    on='asdf_id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Step 2: Add region names for interpretation\n",
    "df_merged = df_merged.merge(\n",
    "    df_names[['asdf_id', 'mun', 'dep']],\n",
    "    on='asdf_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"Merged dataset shape: {df_merged.shape}\")\n",
    "print(f\"Columns: {df_merged.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in IMDS\n",
    "missing_imds = df_merged['imds'].isna().sum()\n",
    "print(f\"Missing IMDS values: {missing_imds}\")\n",
    "\n",
    "# Remove rows with missing IMDS (if any)\n",
    "df_clean = df_merged.dropna(subset=['imds']).copy()\n",
    "print(f\"Valid municipalities for analysis: {len(df_clean)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features (X) and target (y)\n",
    "# Features are the 64 satellite embedding dimensions (A00 to A63)\n",
    "embedding_cols = [f'A{str(i).zfill(2)}' for i in range(64)]\n",
    "\n",
    "X = df_clean[embedding_cols].values\n",
    "y = df_clean['imds'].values\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Target variable shape: {y.shape}\")\n",
    "print(f\"\\nIMDS range: [{y.min():.2f}, {y.max():.2f}]\")\n",
    "print(f\"IMDS mean: {y.mean():.2f} ± {y.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Visualize IMDS Distribution\n",
    "\n",
    "Let's understand the distribution of our target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(y, bins=25, edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(x=y.mean(), color='red', linestyle='--', label=f'Mean: {y.mean():.2f}')\n",
    "axes[0].set_xlabel('IMDS Score')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Distribution of IMDS')\n",
    "axes[0].legend()\n",
    "\n",
    "# Box plot by department\n",
    "df_clean.boxplot(column='imds', by='dep', ax=axes[1], rot=45)\n",
    "axes[1].set_xlabel('Department')\n",
    "axes[1].set_ylabel('IMDS Score')\n",
    "axes[1].set_title('IMDS by Department')\n",
    "plt.suptitle('')  # Remove automatic title\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train-Test Split\n",
    "\n",
    "We split our data into training (80%) and test (20%) sets. The test set will be used for final model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(\n",
    "    X, y, df_clean.index,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_train)} municipalities ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"Test set: {len(X_test)} municipalities ({len(X_test)/len(X)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Configuration\n",
    "\n",
    "We use a **Random Forest Regressor** for this prediction task. Random Forests are well-suited for:\n",
    "\n",
    "- High-dimensional data (64 features)\n",
    "- Capturing non-linear relationships\n",
    "- Providing feature importance rankings\n",
    "- Handling potential interactions between features\n",
    "\n",
    "### Hyperparameters\n",
    "\n",
    "| Parameter | Value | Description |\n",
    "|-----------|-------|-------------|\n",
    "| n_estimators | 100 | Number of trees in the forest |\n",
    "| max_depth | 20 | Maximum depth of each tree |\n",
    "| min_samples_split | 5 | Minimum samples to split a node |\n",
    "| min_samples_leaf | 2 | Minimum samples at leaf nodes |\n",
    "| max_features | sqrt | Features considered per split (~8) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Random Forest model\n",
    "model_params = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 20,\n",
    "    'min_samples_split': 5,\n",
    "    'min_samples_leaf': 2,\n",
    "    'max_features': 'sqrt',\n",
    "    'random_state': RANDOM_STATE,\n",
    "    'n_jobs': -1  # Use all available cores\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "rf_model = RandomForestRegressor(**model_params)\n",
    "\n",
    "print(\"Random Forest model configured with:\")\n",
    "for param, value in model_params.items():\n",
    "    if param not in ['random_state', 'n_jobs']:\n",
    "        print(f\"  - {param}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cross-Validation\n",
    "\n",
    "Before training our final model, we perform **5-fold cross-validation** to get a reliable estimate of model performance. This technique:\n",
    "\n",
    "1. Splits the training data into 5 equal parts (folds)\n",
    "2. Trains on 4 folds and validates on the remaining fold\n",
    "3. Repeats 5 times, using each fold as validation once\n",
    "4. Provides mean and standard deviation of performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup cross-validation\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# Perform cross-validation\n",
    "print(\"Performing 5-fold cross-validation...\")\n",
    "cv_scores = cross_val_score(rf_model, X_train, y_train, cv=cv, scoring='r2')\n",
    "\n",
    "print(\"\\nCross-validation results:\")\n",
    "for i, score in enumerate(cv_scores, 1):\n",
    "    print(f\"  Fold {i}: R² = {score:.4f}\")\n",
    "\n",
    "print(f\"\\nMean CV R²: {cv_scores.mean():.4f} (±{cv_scores.std():.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize cross-validation scores\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(range(1, len(cv_scores)+1), cv_scores, edgecolor='black', alpha=0.7)\n",
    "plt.axhline(y=cv_scores.mean(), color='red', linestyle='--', lw=2, \n",
    "            label=f'Mean: {cv_scores.mean():.4f}')\n",
    "plt.xlabel('Fold', fontsize=11)\n",
    "plt.ylabel('R² Score', fontsize=11)\n",
    "plt.title('Cross-Validation R² Scores', fontsize=12, fontweight='bold')\n",
    "plt.xticks(range(1, len(cv_scores)+1))\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Training and Evaluation\n",
    "\n",
    "Now we train the model on the full training set and evaluate it on the held-out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the full training set\n",
    "print(\"Training Random Forest model...\")\n",
    "rf_model.fit(X_train, y_train)\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_train_pred = rf_model.predict(X_train)\n",
    "y_test_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "# Training set\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "\n",
    "# Test set\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"MODEL PERFORMANCE METRICS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nTraining Set ({len(X_train)} municipalities):\")\n",
    "print(f\"  R² Score:  {train_r2:.4f}\")\n",
    "print(f\"  RMSE:      {train_rmse:.4f} IMDS points\")\n",
    "print(f\"  MAE:       {train_mae:.4f} IMDS points\")\n",
    "\n",
    "print(f\"\\nTest Set ({len(X_test)} municipalities):\")\n",
    "print(f\"  R² Score:  {test_r2:.4f}\")\n",
    "print(f\"  RMSE:      {test_rmse:.4f} IMDS points\")\n",
    "print(f\"  MAE:       {test_mae:.4f} IMDS points\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Understanding the Metrics\n",
    "\n",
    "| Metric | Description | Interpretation |\n",
    "|--------|-------------|----------------|\n",
    "| **R²** | Proportion of variance explained | 0.23 means 23% of IMDS variance is explained by satellite features |\n",
    "| **RMSE** | Root Mean Squared Error | Average prediction error (penalizes large errors more) |\n",
    "| **MAE** | Mean Absolute Error | Average absolute prediction error in IMDS points |\n",
    "\n",
    "**Note**: The gap between training R² (~0.82) and test R² (~0.23) indicates some overfitting, which is common with Random Forests on small datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate prediction errors\n",
    "test_errors = y_test - y_test_pred\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# 1. Actual vs Predicted\n",
    "axes[0].scatter(y_test, y_test_pred, alpha=0.6, edgecolors='k', linewidth=0.5)\n",
    "axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2, label='Perfect prediction')\n",
    "axes[0].set_xlabel('Actual IMDS', fontsize=11)\n",
    "axes[0].set_ylabel('Predicted IMDS', fontsize=11)\n",
    "axes[0].set_title(f'Actual vs Predicted IMDS\\nTest R² = {test_r2:.4f}', fontsize=12, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Residual plot\n",
    "axes[1].scatter(y_test_pred, test_errors, alpha=0.6, edgecolors='k', linewidth=0.5)\n",
    "axes[1].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "axes[1].set_xlabel('Predicted IMDS', fontsize=11)\n",
    "axes[1].set_ylabel('Residuals (Actual - Predicted)', fontsize=11)\n",
    "axes[1].set_title('Residual Plot', fontsize=12, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Error distribution\n",
    "axes[2].hist(test_errors, bins=15, edgecolor='black', alpha=0.7)\n",
    "axes[2].axvline(x=0, color='r', linestyle='--', lw=2)\n",
    "axes[2].set_xlabel('Prediction Error', fontsize=11)\n",
    "axes[2].set_ylabel('Frequency', fontsize=11)\n",
    "axes[2].set_title(f'Distribution of Errors\\nMAE = {test_mae:.2f}', fontsize=12, fontweight='bold')\n",
    "axes[2].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Feature Importance Analysis\n",
    "\n",
    "Random Forests provide built-in feature importance scores based on how much each feature contributes to reducing prediction error across all trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances\n",
    "importances = rf_model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Create feature importance dataframe\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': embedding_cols,\n",
    "    'importance': importances,\n",
    "    'rank': np.argsort(np.argsort(importances)[::-1]) + 1\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Display top 20 features\n",
    "print(\"TOP 20 MOST IMPORTANT FEATURES:\")\n",
    "print(\"=\" * 50)\n",
    "cumulative = 0\n",
    "for i in range(20):\n",
    "    idx = indices[i]\n",
    "    cumulative += importances[idx]\n",
    "    print(f\"{i+1:2d}. {embedding_cols[idx]}: {importances[idx]:.4f} (Cumulative: {cumulative*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cumulative importance\n",
    "cumsum = np.cumsum(importances[indices])\n",
    "n_features_80 = np.argmax(cumsum >= 0.80) + 1\n",
    "\n",
    "print(f\"\\nFeatures needed for 80% importance: {n_features_80}/64 ({n_features_80/64*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# 1. Top 20 feature importances\n",
    "top_n = 20\n",
    "top_indices = indices[:top_n]\n",
    "top_features = [embedding_cols[i] for i in top_indices]\n",
    "top_importances = importances[top_indices]\n",
    "\n",
    "axes[0].barh(range(top_n), top_importances, edgecolor='black')\n",
    "axes[0].set_yticks(range(top_n))\n",
    "axes[0].set_yticklabels(top_features)\n",
    "axes[0].set_xlabel('Importance', fontsize=11)\n",
    "axes[0].set_title('Top 20 Feature Importances', fontsize=12, fontweight='bold')\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# 2. Cumulative importance\n",
    "axes[1].plot(range(1, 65), cumsum, linewidth=2, marker='o', markersize=3)\n",
    "axes[1].axhline(y=0.8, color='r', linestyle='--', lw=2, label='80% threshold')\n",
    "axes[1].axvline(x=n_features_80, color='g', linestyle='--', lw=2, label=f'{n_features_80} features')\n",
    "axes[1].set_xlabel('Number of Features', fontsize=11)\n",
    "axes[1].set_ylabel('Cumulative Importance', fontsize=11)\n",
    "axes[1].set_title('Cumulative Feature Importance', fontsize=12, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Insight: Distributed Feature Importance\n",
    "\n",
    "Unlike more specific indicators (e.g., extreme energy poverty), the IMDS requires many features to capture its variance. This makes sense because IMDS is a composite index combining diverse dimensions of development that manifest in different ways in satellite imagery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Prediction Error Analysis\n",
    "\n",
    "Understanding where the model makes large errors helps us identify patterns and limitations of satellite-based predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results dataframe for test set\n",
    "test_results = df_clean.iloc[idx_test].copy()\n",
    "test_results['imds_actual'] = y_test\n",
    "test_results['imds_predicted'] = y_test_pred\n",
    "test_results['error'] = test_errors\n",
    "test_results['abs_error'] = np.abs(test_errors)\n",
    "\n",
    "print(f\"Test results dataframe created with {len(test_results)} municipalities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 Overpredicted Municipalities\n",
    "\n",
    "These are municipalities where the model predicts **higher** development than the actual IMDS. The satellite features suggest more development than actually exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 overpredicted (model predicts higher than actual)\n",
    "overpredicted = test_results.nsmallest(10, 'error')\n",
    "\n",
    "print(\"TOP 10 OVERPREDICTED MUNICIPALITIES\")\n",
    "print(\"(Model predicts higher development than actual)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for _, row in overpredicted.iterrows():\n",
    "    print(f\"\\n{row['mun']}, {row['dep']}\")\n",
    "    print(f\"  Actual: {row['imds_actual']:.2f} | Predicted: {row['imds_predicted']:.2f} | Error: {row['error']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 Underpredicted Municipalities\n",
    "\n",
    "These are municipalities where the model predicts **lower** development than the actual IMDS. These areas achieve better development outcomes than their satellite features suggest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 underpredicted (model predicts lower than actual)\n",
    "underpredicted = test_results.nlargest(10, 'error')\n",
    "\n",
    "print(\"TOP 10 UNDERPREDICTED MUNICIPALITIES\")\n",
    "print(\"(Model predicts lower development than actual)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for _, row in underpredicted.iterrows():\n",
    "    print(f\"\\n{row['mun']}, {row['dep']}\")\n",
    "    print(f\"  Actual: {row['imds_actual']:.2f} | Predicted: {row['imds_predicted']:.2f} | Error: {row['error']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 Error Patterns by Department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze errors by department\n",
    "dept_errors = test_results.groupby('dep').agg({\n",
    "    'error': ['mean', 'std', 'count'],\n",
    "    'abs_error': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "dept_errors.columns = ['Mean Error', 'Std Error', 'Count', 'Mean Abs Error']\n",
    "dept_errors = dept_errors.sort_values('Mean Error')\n",
    "\n",
    "print(\"PREDICTION ERRORS BY DEPARTMENT:\")\n",
    "print(\"=\" * 60)\n",
    "print(dept_errors.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize errors by department\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "dept_order = dept_errors.sort_values('Mean Error').index\n",
    "colors = ['green' if x > 0 else 'red' for x in dept_errors.loc[dept_order, 'Mean Error']]\n",
    "\n",
    "plt.barh(dept_order, dept_errors.loc[dept_order, 'Mean Error'], color=colors, edgecolor='black', alpha=0.7)\n",
    "plt.axvline(x=0, color='black', linestyle='-', lw=1)\n",
    "plt.xlabel('Mean Prediction Error (Actual - Predicted)', fontsize=11)\n",
    "plt.ylabel('Department', fontsize=11)\n",
    "plt.title('Prediction Errors by Department\\n(Positive = Underpredicted, Negative = Overpredicted)', \n",
    "          fontsize=12, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary and Conclusions\n",
    "\n",
    "### Model Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary table\n",
    "summary = pd.DataFrame({\n",
    "    'Metric': ['Model', 'Target Variable', 'Number of Features', 'Training Samples', 'Test Samples',\n",
    "               'CV Mean R²', 'CV Std R²', 'Test R²', 'Test RMSE', 'Test MAE', 'Features for 80% Importance'],\n",
    "    'Value': ['Random Forest Regressor', 'IMDS (Municipal Sustainable Development Index)', 64,\n",
    "              len(X_train), len(X_test), f\"{cv_scores.mean():.4f}\", f\"{cv_scores.std():.4f}\",\n",
    "              f\"{test_r2:.4f}\", f\"{test_rmse:.4f}\", f\"{test_mae:.4f}\", n_features_80]\n",
    "})\n",
    "\n",
    "print(\"MODEL SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "for _, row in summary.iterrows():\n",
    "    print(f\"{row['Metric']:40s} {row['Value']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Findings\n",
    "\n",
    "1. **Moderate Predictive Power (R² ≈ 23%)**: Satellite embeddings explain about 23% of the variance in IMDS. This is expected because IMDS is a composite index including many dimensions not directly observable from satellite imagery.\n",
    "\n",
    "2. **Urban Centers Systematically Underpredicted**: Cities like La Paz achieve higher development than satellite features suggest. This indicates that institutional services, economic opportunities, and other non-physical development dimensions are concentrated in urban areas.\n",
    "\n",
    "3. **Rural Areas Often Overpredicted**: Some rural municipalities show visible infrastructure in satellite imagery that doesn't translate to actual development outcomes. Factors like isolation, climate, and service access are not captured.\n",
    "\n",
    "4. **Distributed Feature Importance**: Unlike specific indicators, overall development requires many satellite features (44/64 for 80% importance). This reflects the multi-dimensional nature of the IMDS.\n",
    "\n",
    "### Limitations\n",
    "\n",
    "- **Invisible Dimensions**: Many SDG components (governance, education quality, health services, gender equality) are not directly observable from satellite imagery\n",
    "- **Composite Index Complexity**: Aggregating diverse indicators into a single score creates challenges for prediction\n",
    "- **Sample Size**: 339 municipalities may limit model complexity\n",
    "\n",
    "### Practical Applications\n",
    "\n",
    "1. **Screening Tool**: Use satellite predictions to identify areas for detailed surveys\n",
    "2. **Monitoring Physical Development**: Track infrastructure changes over time\n",
    "3. **Complementary Data**: Combine with traditional survey data for comprehensive assessment\n",
    "\n",
    "---\n",
    "\n",
    "## References\n",
    "\n",
    "- **SDG Data Source**: Andersen, L. E., Canelas, S., Gonzales, A., Peñaranda, L. (2020). Atlas municipal de los Objetivos de Desarrollo Sostenible en Bolivia 2020. La Paz: Universidad Privada Boliviana, SDSN Bolivia. https://atlas.sdsnbolivia.org\n",
    "\n",
    "- **DS4Bolivia Repository**: https://github.com/quarcs-lab/ds4bolivia\n",
    "\n",
    "- **Satellite Embeddings**: Google Earth Engine aggregated embeddings at municipal level (2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercises for Students\n",
    "\n",
    "1. **Compare with Other SDG Indices**: Modify this notebook to predict individual SDG indices (e.g., `index_sdg1`, `index_sdg7`). How does predictive power vary across different SDGs?\n",
    "\n",
    "2. **Feature Selection**: Try training the model with only the top 20 features. How does performance change?\n",
    "\n",
    "3. **Alternative Models**: Replace Random Forest with Gradient Boosting (`GradientBoostingRegressor`) or XGBoost. Compare performance.\n",
    "\n",
    "4. **Spatial Analysis**: Create a map showing prediction errors across municipalities. Are there spatial clusters of over/underprediction?\n",
    "\n",
    "5. **Hyperparameter Tuning**: Use `GridSearchCV` or `RandomizedSearchCV` to find optimal hyperparameters. Does performance improve significantly?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
