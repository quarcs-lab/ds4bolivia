{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Comparative SDG Prediction with XGBoost (GPU-Accelerated)\n\n## Predicting All SDG Indicators Using Satellite Embeddings\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/quarcs-lab/ds4bolivia/blob/master/notebooks/predict_all_sdgs_xgb_optuna_cv.ipynb)\n\n---\n\n### Overview\n\nThis notebook performs a **comprehensive comparative analysis** of how well satellite imagery embeddings can predict different Sustainable Development Goal (SDG) indicators across Bolivia's 339 municipalities.\n\n**Research Question**: Which SDG dimensions are most predictable from satellite imagery, and what does this tell us about the relationship between visible landscape features and human development outcomes?\n\n### Methodology\n\n- **Algorithm**: XGBoost with automatic GPU detection\n- **Hyperparameter Tuning**: Optuna with Bayesian optimization (TPE sampler)\n- **Evaluation**: Nested cross-validation (5 outer folds × 3 inner folds)\n- **Features**: 64-dimensional satellite embeddings from Google Earth Engine\n- **Targets**: 16 SDG indicators (IMDS + 15 individual SDG indices)\n\n### Why This Approach?\n\n| Component | Purpose |\n|-----------|--------|\n| **XGBoost** | State-of-the-art gradient boosting, often outperforms Random Forest |\n| **GPU acceleration** | 10-50x speedup enables comprehensive analysis (auto-detected) |\n| **Optuna** | Efficient Bayesian hyperparameter search with pruning |\n| **Nested CV** | Unbiased performance estimates with confidence intervals |\n\n### Expected Runtime\n\n- **A100 GPU**: ~15-30 minutes\n- **T4 GPU**: ~30-60 minutes\n- **CPU only**: ~2-4 hours\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Environment Configuration\n",
    "\n",
    "First, let's verify GPU availability and install the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install required packages with GPU-compatible XGBoost\n# XGBoost 2.0+ has a different API for GPU, so we install a compatible version\n!pip install -q \"xgboost>=2.0.0\" optuna plotly kaleido tqdm\n\n# Verify installation\nimport xgboost as xgb\nprint(f\"XGBoost version installed: {xgb.__version__}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.pruners import MedianPruner\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "import json\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Verify XGBoost version and GPU support\n",
    "print(f\"XGBoost version: {xgb.__version__}\")\n",
    "print(f\"Optuna version: {optuna.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Test XGBoost GPU functionality\n# XGBoost 2.0+ uses 'device' parameter instead of 'tree_method=gpu_hist'\n# For older versions, we fall back to 'tree_method=gpu_hist'\n\nimport subprocess\n\ndef detect_gpu_params():\n    \"\"\"\n    Detect the correct XGBoost GPU parameters based on version and availability.\n    Returns a dict of parameters to use for GPU acceleration.\n    \"\"\"\n    xgb_version = tuple(map(int, xgb.__version__.split('.')[:2]))\n    \n    # Check if CUDA is available\n    try:\n        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n        cuda_available = result.returncode == 0\n    except:\n        cuda_available = False\n    \n    if not cuda_available:\n        print(\"No NVIDIA GPU detected. Using CPU.\")\n        return {'tree_method': 'hist'}, False\n    \n    # Try XGBoost 2.0+ API first (device='cuda')\n    if xgb_version >= (2, 0):\n        try:\n            test_model = xgb.XGBRegressor(\n                device='cuda',\n                tree_method='hist',\n                n_estimators=10,\n                verbosity=0\n            )\n            test_X = np.random.rand(100, 10)\n            test_y = np.random.rand(100)\n            test_model.fit(test_X, test_y)\n            print(f\"✓ GPU acceleration enabled (XGBoost {xgb.__version__}, device='cuda')\")\n            return {'device': 'cuda', 'tree_method': 'hist'}, True\n        except Exception as e:\n            print(f\"XGBoost 2.0+ GPU failed: {e}\")\n    \n    # Try legacy API (tree_method='gpu_hist')\n    try:\n        test_model = xgb.XGBRegressor(\n            tree_method='gpu_hist',\n            n_estimators=10,\n            verbosity=0\n        )\n        test_X = np.random.rand(100, 10)\n        test_y = np.random.rand(100)\n        test_model.fit(test_X, test_y)\n        print(f\"✓ GPU acceleration enabled (XGBoost {xgb.__version__}, tree_method='gpu_hist')\")\n        return {'tree_method': 'gpu_hist'}, True\n    except Exception as e:\n        print(f\"Legacy GPU API failed: {e}\")\n    \n    # Fall back to CPU\n    print(\"GPU not available, using CPU (tree_method='hist')\")\n    return {'tree_method': 'hist'}, False\n\n# Detect GPU configuration\nGPU_PARAMS, GPU_AVAILABLE = detect_gpu_params()\nprint(f\"\\nGPU Parameters: {GPU_PARAMS}\")\nprint(f\"GPU Available: {GPU_AVAILABLE}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading & Preprocessing\n",
    "\n",
    "We load three datasets from the DS4Bolivia repository:\n",
    "1. **SDG indices** - Our 16 target variables\n",
    "2. **Satellite embeddings** - Our 64 feature variables\n",
    "3. **Region names** - For interpretation of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets from GitHub\n",
    "print(\"Loading datasets...\")\n",
    "\n",
    "# SDG indices (contains all target variables)\n",
    "url_sdg = \"https://raw.githubusercontent.com/quarcs-lab/ds4bolivia/master/sdg/sdg.csv\"\n",
    "df_sdg = pd.read_csv(url_sdg)\n",
    "print(f\"  SDG data: {df_sdg.shape[0]} municipalities, {df_sdg.shape[1]} columns\")\n",
    "\n",
    "# Satellite embeddings (64-dimensional features)\n",
    "url_emb = \"https://raw.githubusercontent.com/quarcs-lab/ds4bolivia/master/satelliteEmbeddings/satelliteEmbeddings2017.csv\"\n",
    "df_embeddings = pd.read_csv(url_emb)\n",
    "print(f\"  Satellite embeddings: {df_embeddings.shape[0]} municipalities, {df_embeddings.shape[1]} columns\")\n",
    "\n",
    "# Region names for interpretation\n",
    "url_names = \"https://raw.githubusercontent.com/quarcs-lab/ds4bolivia/master/regionNames/regionNames.csv\"\n",
    "df_names = pd.read_csv(url_names)\n",
    "print(f\"  Region names: {df_names.shape[0]} municipalities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target variables (all SDG indicators)\n",
    "TARGET_VARIABLES = [\n",
    "    'imds',          # Municipal Sustainable Development Index (composite)\n",
    "    'index_sdg1',    # No Poverty\n",
    "    'index_sdg2',    # Zero Hunger\n",
    "    'index_sdg3',    # Good Health and Well-being\n",
    "    'index_sdg4',    # Quality Education\n",
    "    'index_sdg5',    # Gender Equality\n",
    "    'index_sdg6',    # Clean Water and Sanitation\n",
    "    'index_sdg7',    # Affordable and Clean Energy\n",
    "    'index_sdg8',    # Decent Work and Economic Growth\n",
    "    'index_sdg9',    # Industry, Innovation and Infrastructure\n",
    "    'index_sdg10',   # Reduced Inequalities\n",
    "    'index_sdg11',   # Sustainable Cities and Communities\n",
    "    'index_sdg13',   # Climate Action\n",
    "    'index_sdg15',   # Life on Land\n",
    "    'index_sdg16',   # Peace, Justice and Strong Institutions\n",
    "    'index_sdg17',   # Partnerships for the Goals\n",
    "]\n",
    "\n",
    "# SDG descriptions for visualization\n",
    "SDG_DESCRIPTIONS = {\n",
    "    'imds': 'IMDS (Composite)',\n",
    "    'index_sdg1': 'SDG 1: No Poverty',\n",
    "    'index_sdg2': 'SDG 2: Zero Hunger',\n",
    "    'index_sdg3': 'SDG 3: Good Health',\n",
    "    'index_sdg4': 'SDG 4: Quality Education',\n",
    "    'index_sdg5': 'SDG 5: Gender Equality',\n",
    "    'index_sdg6': 'SDG 6: Clean Water',\n",
    "    'index_sdg7': 'SDG 7: Clean Energy',\n",
    "    'index_sdg8': 'SDG 8: Decent Work',\n",
    "    'index_sdg9': 'SDG 9: Innovation',\n",
    "    'index_sdg10': 'SDG 10: Reduced Inequalities',\n",
    "    'index_sdg11': 'SDG 11: Sustainable Cities',\n",
    "    'index_sdg13': 'SDG 13: Climate Action',\n",
    "    'index_sdg15': 'SDG 15: Life on Land',\n",
    "    'index_sdg16': 'SDG 16: Peace & Justice',\n",
    "    'index_sdg17': 'SDG 17: Partnerships',\n",
    "}\n",
    "\n",
    "# SDG categories for grouped analysis\n",
    "SDG_CATEGORIES = {\n",
    "    'imds': 'Composite',\n",
    "    'index_sdg1': 'Economic',\n",
    "    'index_sdg2': 'Social',\n",
    "    'index_sdg3': 'Social',\n",
    "    'index_sdg4': 'Social',\n",
    "    'index_sdg5': 'Social',\n",
    "    'index_sdg6': 'Environmental',\n",
    "    'index_sdg7': 'Environmental',\n",
    "    'index_sdg8': 'Economic',\n",
    "    'index_sdg9': 'Economic',\n",
    "    'index_sdg10': 'Economic',\n",
    "    'index_sdg11': 'Environmental',\n",
    "    'index_sdg13': 'Environmental',\n",
    "    'index_sdg15': 'Environmental',\n",
    "    'index_sdg16': 'Governance',\n",
    "    'index_sdg17': 'Governance',\n",
    "}\n",
    "\n",
    "print(f\"\\nTarget variables: {len(TARGET_VARIABLES)}\")\n",
    "for var in TARGET_VARIABLES:\n",
    "    print(f\"  - {var}: {SDG_DESCRIPTIONS[var]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge datasets\n",
    "df_merged = df_sdg.merge(\n",
    "    df_embeddings,\n",
    "    on='asdf_id',\n",
    "    how='inner'\n",
    ")\n",
    "df_merged = df_merged.merge(\n",
    "    df_names[['asdf_id', 'mun', 'dep']],\n",
    "    on='asdf_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"Merged dataset: {df_merged.shape[0]} municipalities\")\n",
    "\n",
    "# Define feature columns (satellite embeddings)\n",
    "FEATURE_COLS = [f'A{str(i).zfill(2)}' for i in range(64)]\n",
    "print(f\"Feature columns: {len(FEATURE_COLS)} satellite embeddings (A00-A63)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze data availability for each target variable\n",
    "print(\"\\nData availability per SDG indicator:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "data_availability = []\n",
    "for var in TARGET_VARIABLES:\n",
    "    n_valid = df_merged[var].notna().sum()\n",
    "    n_missing = df_merged[var].isna().sum()\n",
    "    pct_valid = n_valid / len(df_merged) * 100\n",
    "    \n",
    "    if n_valid > 0:\n",
    "        var_mean = df_merged[var].mean()\n",
    "        var_std = df_merged[var].std()\n",
    "    else:\n",
    "        var_mean = var_std = np.nan\n",
    "    \n",
    "    data_availability.append({\n",
    "        'variable': var,\n",
    "        'description': SDG_DESCRIPTIONS[var],\n",
    "        'n_valid': n_valid,\n",
    "        'n_missing': n_missing,\n",
    "        'pct_valid': pct_valid,\n",
    "        'mean': var_mean,\n",
    "        'std': var_std\n",
    "    })\n",
    "    \n",
    "    print(f\"{SDG_DESCRIPTIONS[var]:<30} | Valid: {n_valid:>3} | Missing: {n_missing:>3} | Mean: {var_mean:>6.2f} | Std: {var_std:>5.2f}\")\n",
    "\n",
    "df_availability = pd.DataFrame(data_availability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. XGBoost Configuration & Optuna Objective Function\n",
    "\n",
    "### Understanding the Hyperparameter Search Space\n",
    "\n",
    "XGBoost has many hyperparameters that control model complexity and regularization:\n",
    "\n",
    "| Parameter | Range | Purpose |\n",
    "|-----------|-------|--------|\n",
    "| `n_estimators` | [100, 1000] | Number of boosting rounds |\n",
    "| `max_depth` | [3, 15] | Maximum tree depth (complexity) |\n",
    "| `learning_rate` | [0.01, 0.3] | Step size shrinkage (η) |\n",
    "| `min_child_weight` | [1, 10] | Minimum sum of instance weight in a child |\n",
    "| `subsample` | [0.6, 1.0] | Row subsampling ratio |\n",
    "| `colsample_bytree` | [0.6, 1.0] | Column subsampling ratio |\n",
    "| `reg_alpha` | [1e-8, 10] | L1 regularization (Lasso) |\n",
    "| `reg_lambda` | [1e-8, 10] | L2 regularization (Ridge) |\n",
    "| `gamma` | [1e-8, 5] | Minimum loss reduction for split |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def create_objective(X_train_fold, y_train_fold, inner_cv):\n    \"\"\"\n    Factory function that creates an Optuna objective for a specific training fold.\n    \n    This pattern is necessary because:\n    1. Optuna's objective function only takes a 'trial' parameter\n    2. We need to pass fold-specific training data\n    3. The closure captures X_train_fold and y_train_fold\n    \n    Parameters:\n    -----------\n    X_train_fold : array-like\n        Features for this outer fold's training set\n    y_train_fold : array-like\n        Target for this outer fold's training set\n    inner_cv : KFold\n        Cross-validation splitter for inner loop\n    \n    Returns:\n    --------\n    objective : function\n        Objective function for Optuna optimization\n    \"\"\"\n    \n    def objective(trial):\n        # Sample hyperparameters from search space\n        params = {\n            'n_estimators': trial.suggest_int('n_estimators', 50, 500, step=50),\n            'max_depth': trial.suggest_int('max_depth', 3, 12),\n            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n            'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n            'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n            'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n            'gamma': trial.suggest_float('gamma', 1e-8, 5.0, log=True),\n            # Fixed parameters - use detected GPU params\n            **GPU_PARAMS,\n            'objective': 'reg:squarederror',\n            'eval_metric': 'rmse',\n            'verbosity': 0,\n            'random_state': RANDOM_STATE,\n        }\n        \n        # Create model with sampled parameters\n        model = xgb.XGBRegressor(**params)\n        \n        # Evaluate using inner cross-validation\n        try:\n            cv_scores = cross_val_score(\n                model, X_train_fold, y_train_fold,\n                cv=inner_cv,\n                scoring='r2',\n                n_jobs=1  # GPU handles parallelism\n            )\n            return cv_scores.mean()\n        except Exception as e:\n            # Return a very low score if model fails\n            return -1.0\n    \n    return objective"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def run_nested_cv_for_target(X, y, target_name, n_outer_folds=5, n_inner_folds=5, n_trials=50):\n    \"\"\"\n    Run nested cross-validation with Optuna hyperparameter tuning for a single target.\n    \n    Nested CV Structure:\n    - Outer loop: K-fold CV for unbiased performance estimation\n      - Inner loop: K-fold CV within Optuna for hyperparameter tuning\n    \n    Parameters:\n    -----------\n    X : array-like\n        Feature matrix (n_samples, 64)\n    y : array-like\n        Target variable (n_samples,)\n    target_name : str\n        Name of the target variable (for logging)\n    n_outer_folds : int\n        Number of outer CV folds\n    n_inner_folds : int\n        Number of inner CV folds for Optuna\n    n_trials : int\n        Number of Optuna trials per outer fold\n    \n    Returns:\n    --------\n    results : dict\n        Dictionary containing metrics, best params, and predictions\n    \"\"\"\n    \n    # Setup cross-validation\n    outer_cv = KFold(n_splits=n_outer_folds, shuffle=True, random_state=RANDOM_STATE)\n    inner_cv = KFold(n_splits=n_inner_folds, shuffle=True, random_state=RANDOM_STATE)\n    \n    # Storage for results\n    fold_r2_scores = []\n    fold_rmse_scores = []\n    fold_mae_scores = []\n    fold_best_params = []\n    all_predictions = np.zeros_like(y)\n    all_feature_importances = []\n    \n    # Outer cross-validation loop\n    for fold_idx, (train_idx, test_idx) in enumerate(outer_cv.split(X)):\n        \n        # Split data for this outer fold\n        X_train_fold, X_test_fold = X[train_idx], X[test_idx]\n        y_train_fold, y_test_fold = y[train_idx], y[test_idx]\n        \n        # Create Optuna study for this fold\n        study = optuna.create_study(\n            direction='maximize',\n            sampler=TPESampler(seed=RANDOM_STATE + fold_idx),\n            pruner=MedianPruner(n_startup_trials=5, n_warmup_steps=3)\n        )\n        \n        # Create objective function for this fold\n        objective = create_objective(X_train_fold, y_train_fold, inner_cv)\n        \n        # Run optimization\n        study.optimize(objective, n_trials=n_trials, show_progress_bar=False)\n        \n        # Get best parameters\n        best_params = study.best_params.copy()\n        best_params.update({\n            **GPU_PARAMS,\n            'objective': 'reg:squarederror',\n            'verbosity': 0,\n            'random_state': RANDOM_STATE,\n        })\n        fold_best_params.append(best_params)\n        \n        # Train final model with best parameters on full training fold\n        final_model = xgb.XGBRegressor(**best_params)\n        final_model.fit(X_train_fold, y_train_fold)\n        \n        # Evaluate on test fold\n        y_pred = final_model.predict(X_test_fold)\n        all_predictions[test_idx] = y_pred\n        \n        # Calculate metrics\n        fold_r2 = r2_score(y_test_fold, y_pred)\n        fold_rmse = np.sqrt(mean_squared_error(y_test_fold, y_pred))\n        fold_mae = mean_absolute_error(y_test_fold, y_pred)\n        \n        fold_r2_scores.append(fold_r2)\n        fold_rmse_scores.append(fold_rmse)\n        fold_mae_scores.append(fold_mae)\n        \n        # Store feature importances\n        all_feature_importances.append(final_model.feature_importances_)\n    \n    # Aggregate results\n    r2_mean = np.mean(fold_r2_scores)\n    r2_std = np.std(fold_r2_scores)\n    r2_ci_lower = r2_mean - 1.96 * r2_std / np.sqrt(n_outer_folds)\n    r2_ci_upper = r2_mean + 1.96 * r2_std / np.sqrt(n_outer_folds)\n    \n    rmse_mean = np.mean(fold_rmse_scores)\n    rmse_std = np.std(fold_rmse_scores)\n    \n    mae_mean = np.mean(fold_mae_scores)\n    mae_std = np.std(fold_mae_scores)\n    \n    # Average feature importances across folds\n    avg_feature_importances = np.mean(all_feature_importances, axis=0)\n    \n    return {\n        'target': target_name,\n        'n_samples': len(y),\n        'r2_mean': r2_mean,\n        'r2_std': r2_std,\n        'r2_ci_lower': r2_ci_lower,\n        'r2_ci_upper': r2_ci_upper,\n        'rmse_mean': rmse_mean,\n        'rmse_std': rmse_std,\n        'mae_mean': mae_mean,\n        'mae_std': mae_std,\n        'fold_r2_scores': fold_r2_scores,\n        'fold_rmse_scores': fold_rmse_scores,\n        'fold_mae_scores': fold_mae_scores,\n        'best_params_per_fold': fold_best_params,\n        'predictions': all_predictions,\n        'feature_importances': avg_feature_importances,\n    }"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Main Execution: Predict All SDG Indicators\n\nNow we run the nested cross-validation with Optuna for all 16 SDG indicators. This is the computationally intensive part of the notebook.\n\n**Configuration:**\n- 5 outer folds × 3 inner folds × 50 trials = 750 model fits per SDG\n- 16 SDGs × 750 = 12,000 total model fits\n- With GPU acceleration, this takes ~15-30 minutes on A100\n- Without GPU (CPU only), expect 2-4 hours"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Configuration for nested CV\n# Reduced from original to speed up execution while maintaining rigor\nN_OUTER_FOLDS = 5\nN_INNER_FOLDS = 3  # Reduced from 5 to speed up inner optimization\nN_TRIALS = 50      # Reduced from 100 - still provides good optimization\n\n# Calculate total model fits\ntotal_fits = len(TARGET_VARIABLES) * N_OUTER_FOLDS * N_TRIALS * N_INNER_FOLDS\n\nprint(\"=\"*80)\nprint(\"COMPARATIVE SDG PREDICTION WITH XGBOOST\")\nprint(\"=\"*80)\nprint(f\"\\nConfiguration:\")\nprint(f\"  - Outer CV folds: {N_OUTER_FOLDS}\")\nprint(f\"  - Inner CV folds: {N_INNER_FOLDS}\")\nprint(f\"  - Optuna trials per fold: {N_TRIALS}\")\nprint(f\"  - Target variables: {len(TARGET_VARIABLES)}\")\nprint(f\"  - Total model fits (estimated): {total_fits:,}\")\nprint(f\"  - GPU acceleration: {GPU_AVAILABLE}\")\nprint(f\"  - GPU parameters: {GPU_PARAMS}\")\n\n# Estimate runtime\nif GPU_AVAILABLE:\n    est_time = \"15-30 minutes\"\nelse:\n    est_time = \"2-4 hours\"\nprint(f\"  - Estimated runtime: {est_time}\")\nprint()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run prediction for all SDG indicators\n",
    "all_results = []\n",
    "feature_importance_matrix = []  # 16 SDGs × 64 features\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i, target_var in enumerate(tqdm(TARGET_VARIABLES, desc=\"Processing SDGs\")):\n",
    "    \n",
    "    print(f\"\\n[{i+1}/{len(TARGET_VARIABLES)}] Processing {SDG_DESCRIPTIONS[target_var]}...\")\n",
    "    \n",
    "    # Prepare data for this target (remove missing values)\n",
    "    mask = df_merged[target_var].notna()\n",
    "    X = df_merged.loc[mask, FEATURE_COLS].values\n",
    "    y = df_merged.loc[mask, target_var].values\n",
    "    \n",
    "    if len(y) < 50:  # Skip if too few samples\n",
    "        print(f\"  Skipping: only {len(y)} valid samples\")\n",
    "        continue\n",
    "    \n",
    "    # Run nested CV with Optuna\n",
    "    target_start = time.time()\n",
    "    results = run_nested_cv_for_target(\n",
    "        X, y, target_var,\n",
    "        n_outer_folds=N_OUTER_FOLDS,\n",
    "        n_inner_folds=N_INNER_FOLDS,\n",
    "        n_trials=N_TRIALS\n",
    "    )\n",
    "    target_time = time.time() - target_start\n",
    "    \n",
    "    # Add metadata\n",
    "    results['description'] = SDG_DESCRIPTIONS[target_var]\n",
    "    results['category'] = SDG_CATEGORIES[target_var]\n",
    "    results['time_seconds'] = target_time\n",
    "    \n",
    "    all_results.append(results)\n",
    "    feature_importance_matrix.append(results['feature_importances'])\n",
    "    \n",
    "    # Print progress\n",
    "    print(f\"  R² = {results['r2_mean']:.4f} (±{results['r2_std']:.4f}) | \"\n",
    "          f\"MAE = {results['mae_mean']:.2f} | \"\n",
    "          f\"Time: {target_time:.1f}s\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Total execution time: {total_time/60:.1f} minutes\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Results Compilation\n",
    "\n",
    "Let's compile all results into a structured DataFrame and rank the SDGs by predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results DataFrame\n",
    "results_data = []\n",
    "\n",
    "for r in all_results:\n",
    "    results_data.append({\n",
    "        'variable': r['target'],\n",
    "        'description': r['description'],\n",
    "        'category': r['category'],\n",
    "        'n_samples': r['n_samples'],\n",
    "        'r2_mean': r['r2_mean'],\n",
    "        'r2_std': r['r2_std'],\n",
    "        'r2_ci_lower': r['r2_ci_lower'],\n",
    "        'r2_ci_upper': r['r2_ci_upper'],\n",
    "        'rmse_mean': r['rmse_mean'],\n",
    "        'rmse_std': r['rmse_std'],\n",
    "        'mae_mean': r['mae_mean'],\n",
    "        'mae_std': r['mae_std'],\n",
    "        'time_seconds': r['time_seconds'],\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results_data)\n",
    "\n",
    "# Add ranking\n",
    "df_results['rank'] = df_results['r2_mean'].rank(ascending=False).astype(int)\n",
    "df_results = df_results.sort_values('rank')\n",
    "\n",
    "# Add predictability category\n",
    "def categorize_predictability(r2):\n",
    "    if r2 >= 0.4:\n",
    "        return 'High'\n",
    "    elif r2 >= 0.25:\n",
    "        return 'Medium'\n",
    "    elif r2 >= 0.1:\n",
    "        return 'Low'\n",
    "    else:\n",
    "        return 'Very Low'\n",
    "\n",
    "df_results['predictability'] = df_results['r2_mean'].apply(categorize_predictability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary table\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"COMPARATIVE RESULTS: SDG PREDICTABILITY FROM SATELLITE EMBEDDINGS\")\n",
    "print(\"=\"*100)\n",
    "print()\n",
    "\n",
    "# Format for display\n",
    "display_cols = ['rank', 'description', 'category', 'n_samples', 'r2_mean', 'r2_std', 'mae_mean', 'predictability']\n",
    "df_display = df_results[display_cols].copy()\n",
    "df_display.columns = ['Rank', 'SDG', 'Category', 'N', 'R² Mean', 'R² Std', 'MAE', 'Predictability']\n",
    "\n",
    "# Print table\n",
    "print(df_display.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics by category\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PREDICTABILITY BY SDG CATEGORY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "category_summary = df_results.groupby('category').agg({\n",
    "    'r2_mean': ['mean', 'std', 'min', 'max'],\n",
    "    'mae_mean': 'mean',\n",
    "    'variable': 'count'\n",
    "}).round(4)\n",
    "\n",
    "category_summary.columns = ['R² Mean', 'R² Std', 'R² Min', 'R² Max', 'MAE Mean', 'Count']\n",
    "print(category_summary.sort_values('R² Mean', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualizations\n",
    "\n",
    "Let's create comprehensive visualizations to understand the comparative predictability of different SDGs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the figure with multiple subplots\n",
    "fig = plt.figure(figsize=(20, 24))\n",
    "\n",
    "# Color palette for categories\n",
    "category_colors = {\n",
    "    'Economic': '#2ecc71',\n",
    "    'Social': '#3498db',\n",
    "    'Environmental': '#e74c3c',\n",
    "    'Governance': '#9b59b6',\n",
    "    'Composite': '#f39c12'\n",
    "}\n",
    "\n",
    "# ============================================================\n",
    "# Plot 1: R² Comparison (Horizontal Bar Chart)\n",
    "# ============================================================\n",
    "ax1 = plt.subplot(3, 2, 1)\n",
    "\n",
    "# Sort by R² for display\n",
    "df_sorted = df_results.sort_values('r2_mean', ascending=True)\n",
    "\n",
    "colors = [category_colors[cat] for cat in df_sorted['category']]\n",
    "bars = ax1.barh(range(len(df_sorted)), df_sorted['r2_mean'], \n",
    "                xerr=df_sorted['r2_std'], capsize=3, color=colors, edgecolor='black', alpha=0.8)\n",
    "\n",
    "ax1.set_yticks(range(len(df_sorted)))\n",
    "ax1.set_yticklabels(df_sorted['description'], fontsize=10)\n",
    "ax1.set_xlabel('R² Score (Cross-Validation Mean)', fontsize=12)\n",
    "ax1.set_title('Predictability of SDG Indicators from Satellite Embeddings\\n(with standard deviation error bars)', \n",
    "              fontsize=14, fontweight='bold')\n",
    "ax1.axvline(x=0, color='gray', linestyle='--', alpha=0.5)\n",
    "ax1.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Add legend for categories\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor=color, edgecolor='black', label=cat) \n",
    "                   for cat, color in category_colors.items()]\n",
    "ax1.legend(handles=legend_elements, loc='lower right', title='Category')\n",
    "\n",
    "# ============================================================\n",
    "# Plot 2: R² with 95% Confidence Intervals\n",
    "# ============================================================\n",
    "ax2 = plt.subplot(3, 2, 2)\n",
    "\n",
    "x_pos = range(len(df_sorted))\n",
    "ax2.errorbar(df_sorted['r2_mean'], x_pos, \n",
    "             xerr=[df_sorted['r2_mean'] - df_sorted['r2_ci_lower'],\n",
    "                   df_sorted['r2_ci_upper'] - df_sorted['r2_mean']],\n",
    "             fmt='o', capsize=5, capthick=2, markersize=8,\n",
    "             color='darkblue', ecolor='steelblue')\n",
    "\n",
    "ax2.set_yticks(x_pos)\n",
    "ax2.set_yticklabels(df_sorted['description'], fontsize=10)\n",
    "ax2.set_xlabel('R² Score', fontsize=12)\n",
    "ax2.set_title('R² with 95% Confidence Intervals', fontsize=14, fontweight='bold')\n",
    "ax2.axvline(x=0, color='gray', linestyle='--', alpha=0.5)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# ============================================================\n",
    "# Plot 3: Category Comparison (Box Plot)\n",
    "# ============================================================\n",
    "ax3 = plt.subplot(3, 2, 3)\n",
    "\n",
    "category_order = ['Economic', 'Environmental', 'Social', 'Governance', 'Composite']\n",
    "df_plot = df_results[df_results['category'].isin(category_order)].copy()\n",
    "\n",
    "# Create box plot data\n",
    "box_data = [df_plot[df_plot['category'] == cat]['r2_mean'].values for cat in category_order if cat in df_plot['category'].values]\n",
    "box_labels = [cat for cat in category_order if cat in df_plot['category'].values]\n",
    "box_colors = [category_colors[cat] for cat in box_labels]\n",
    "\n",
    "bp = ax3.boxplot(box_data, labels=box_labels, patch_artist=True)\n",
    "for patch, color in zip(bp['boxes'], box_colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.7)\n",
    "\n",
    "ax3.set_ylabel('R² Score', fontsize=12)\n",
    "ax3.set_title('Predictability by SDG Category', fontsize=14, fontweight='bold')\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# ============================================================\n",
    "# Plot 4: R² vs Sample Size\n",
    "# ============================================================\n",
    "ax4 = plt.subplot(3, 2, 4)\n",
    "\n",
    "for cat in category_colors:\n",
    "    mask = df_results['category'] == cat\n",
    "    ax4.scatter(df_results.loc[mask, 'n_samples'], \n",
    "                df_results.loc[mask, 'r2_mean'],\n",
    "                c=category_colors[cat], label=cat, s=100, edgecolors='black', alpha=0.8)\n",
    "\n",
    "ax4.set_xlabel('Number of Valid Samples', fontsize=12)\n",
    "ax4.set_ylabel('R² Score', fontsize=12)\n",
    "ax4.set_title('Predictability vs Data Availability', fontsize=14, fontweight='bold')\n",
    "ax4.legend(title='Category')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# ============================================================\n",
    "# Plot 5: MAE Comparison\n",
    "# ============================================================\n",
    "ax5 = plt.subplot(3, 2, 5)\n",
    "\n",
    "df_mae_sorted = df_results.sort_values('mae_mean', ascending=False)\n",
    "colors_mae = [category_colors[cat] for cat in df_mae_sorted['category']]\n",
    "\n",
    "ax5.barh(range(len(df_mae_sorted)), df_mae_sorted['mae_mean'], \n",
    "         xerr=df_mae_sorted['mae_std'], capsize=3, color=colors_mae, edgecolor='black', alpha=0.8)\n",
    "\n",
    "ax5.set_yticks(range(len(df_mae_sorted)))\n",
    "ax5.set_yticklabels(df_mae_sorted['description'], fontsize=10)\n",
    "ax5.set_xlabel('Mean Absolute Error (MAE)', fontsize=12)\n",
    "ax5.set_title('Prediction Error by SDG Indicator', fontsize=14, fontweight='bold')\n",
    "ax5.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# ============================================================\n",
    "# Plot 6: Fold-by-Fold Stability\n",
    "# ============================================================\n",
    "ax6 = plt.subplot(3, 2, 6)\n",
    "\n",
    "# Plot R² across folds for each SDG\n",
    "for i, r in enumerate(all_results):\n",
    "    color = category_colors[r['category']]\n",
    "    ax6.plot(range(1, N_OUTER_FOLDS + 1), r['fold_r2_scores'], \n",
    "             marker='o', label=r['description'] if i < 5 else None,\n",
    "             color=color, alpha=0.7)\n",
    "\n",
    "ax6.set_xlabel('Fold Number', fontsize=12)\n",
    "ax6.set_ylabel('R² Score', fontsize=12)\n",
    "ax6.set_title('Cross-Validation Stability Across Folds', fontsize=14, fontweight='bold')\n",
    "ax6.set_xticks(range(1, N_OUTER_FOLDS + 1))\n",
    "ax6.grid(True, alpha=0.3)\n",
    "ax6.legend(loc='upper right', fontsize=8, ncol=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('all_sdgs_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nVisualization saved: all_sdgs_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Importance Analysis\n",
    "\n",
    "Let's analyze which satellite embedding dimensions are most predictive across all SDGs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature importance matrix (16 SDGs × 64 features)\n",
    "feature_importance_df = pd.DataFrame(\n",
    "    feature_importance_matrix,\n",
    "    columns=FEATURE_COLS,\n",
    "    index=[r['target'] for r in all_results]\n",
    ")\n",
    "\n",
    "print(f\"Feature importance matrix shape: {feature_importance_df.shape}\")\n",
    "print(f\"  - Rows: {feature_importance_df.shape[0]} SDG indicators\")\n",
    "print(f\"  - Columns: {feature_importance_df.shape[1]} satellite features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate aggregate importance across all SDGs\n",
    "aggregate_importance = feature_importance_df.mean(axis=0).sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nTOP 20 MOST IMPORTANT FEATURES (AVERAGED ACROSS ALL SDGs)\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Rank':<6} {'Feature':<10} {'Importance':<12} {'Cumulative %'}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "cumulative = 0\n",
    "for i, (feat, imp) in enumerate(aggregate_importance.head(20).items()):\n",
    "    cumulative += imp\n",
    "    print(f\"{i+1:<6} {feat:<10} {imp:.6f}     {cumulative*100:.2f}%\")\n",
    "\n",
    "# How many features for 80% importance?\n",
    "cumsum = np.cumsum(aggregate_importance.values)\n",
    "n_features_80 = np.argmax(cumsum >= 0.80) + 1\n",
    "print(f\"\\nFeatures needed for 80% total importance: {n_features_80}/64 ({n_features_80/64*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature importance heatmap\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "# Heatmap: All features × All SDGs\n",
    "ax1 = axes[0]\n",
    "\n",
    "# Sort features by aggregate importance and SDGs by R²\n",
    "top_features = aggregate_importance.head(30).index.tolist()\n",
    "sdg_order = df_results.sort_values('r2_mean', ascending=False)['variable'].tolist()\n",
    "\n",
    "heatmap_data = feature_importance_df.loc[sdg_order, top_features]\n",
    "\n",
    "sns.heatmap(heatmap_data, ax=ax1, cmap='YlOrRd', \n",
    "            xticklabels=top_features, \n",
    "            yticklabels=[SDG_DESCRIPTIONS[v] for v in sdg_order],\n",
    "            cbar_kws={'label': 'Feature Importance'})\n",
    "ax1.set_title('Feature Importance by SDG (Top 30 Features)', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Satellite Embedding Feature', fontsize=12)\n",
    "ax1.set_ylabel('SDG Indicator (sorted by R²)', fontsize=12)\n",
    "plt.setp(ax1.get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "# Bar chart: Aggregate importance\n",
    "ax2 = axes[1]\n",
    "\n",
    "top_20_features = aggregate_importance.head(20)\n",
    "bars = ax2.barh(range(len(top_20_features)), top_20_features.values, \n",
    "                color='steelblue', edgecolor='black', alpha=0.8)\n",
    "ax2.set_yticks(range(len(top_20_features)))\n",
    "ax2.set_yticklabels(top_20_features.index, fontsize=11)\n",
    "ax2.set_xlabel('Average Feature Importance', fontsize=12)\n",
    "ax2.set_title('Top 20 Features (Averaged Across All SDGs)', fontsize=14, fontweight='bold')\n",
    "ax2.invert_yaxis()\n",
    "ax2.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nVisualization saved: feature_importance_analysis.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify SDG-specific vs universal features\n",
    "print(\"\\nFEATURE SPECIFICITY ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate coefficient of variation for each feature across SDGs\n",
    "feature_cv = feature_importance_df.std(axis=0) / feature_importance_df.mean(axis=0)\n",
    "feature_cv = feature_cv.sort_values()\n",
    "\n",
    "print(\"\\nMost UNIVERSAL features (low variance across SDGs):\")\n",
    "print(\"-\" * 50)\n",
    "for feat in feature_cv.head(10).index:\n",
    "    mean_imp = feature_importance_df[feat].mean()\n",
    "    std_imp = feature_importance_df[feat].std()\n",
    "    print(f\"  {feat}: importance = {mean_imp:.4f} (±{std_imp:.4f})\")\n",
    "\n",
    "print(\"\\nMost SDG-SPECIFIC features (high variance across SDGs):\")\n",
    "print(\"-\" * 50)\n",
    "for feat in feature_cv.tail(10).index[::-1]:\n",
    "    mean_imp = feature_importance_df[feat].mean()\n",
    "    std_imp = feature_importance_df[feat].std()\n",
    "    # Find which SDG uses this feature most\n",
    "    top_sdg = feature_importance_df[feat].idxmax()\n",
    "    print(f\"  {feat}: importance = {mean_imp:.4f} (±{std_imp:.4f}) | Most important for: {SDG_DESCRIPTIONS[top_sdg]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Hyperparameter Analysis\n",
    "\n",
    "Let's examine the optimal hyperparameters found for each SDG and identify patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract best hyperparameters (using first fold's params as representative)\n",
    "hyperparam_data = []\n",
    "\n",
    "for r in all_results:\n",
    "    # Average across folds for each hyperparameter\n",
    "    avg_params = {}\n",
    "    for param in ['n_estimators', 'max_depth', 'learning_rate', 'min_child_weight', \n",
    "                  'subsample', 'colsample_bytree', 'reg_alpha', 'reg_lambda', 'gamma']:\n",
    "        values = [fold_params.get(param, np.nan) for fold_params in r['best_params_per_fold']]\n",
    "        avg_params[param] = np.mean(values)\n",
    "    \n",
    "    avg_params['sdg'] = r['target']\n",
    "    avg_params['description'] = r['description']\n",
    "    avg_params['r2'] = r['r2_mean']\n",
    "    hyperparam_data.append(avg_params)\n",
    "\n",
    "df_hyperparams = pd.DataFrame(hyperparam_data)\n",
    "df_hyperparams = df_hyperparams.sort_values('r2', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display hyperparameter summary\n",
    "print(\"\\nOPTIMAL HYPERPARAMETERS BY SDG\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "display_params = ['description', 'r2', 'n_estimators', 'max_depth', 'learning_rate', 'subsample']\n",
    "print(df_hyperparams[display_params].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize hyperparameter patterns\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "params_to_plot = ['n_estimators', 'max_depth', 'learning_rate', 'subsample', 'colsample_bytree', 'reg_lambda']\n",
    "param_labels = ['Number of Trees', 'Max Depth', 'Learning Rate', 'Subsample Ratio', 'Column Sample Ratio', 'L2 Regularization']\n",
    "\n",
    "for ax, param, label in zip(axes.flat, params_to_plot, param_labels):\n",
    "    ax.scatter(df_hyperparams['r2'], df_hyperparams[param], \n",
    "               c='steelblue', s=80, edgecolors='black', alpha=0.7)\n",
    "    ax.set_xlabel('R² Score', fontsize=11)\n",
    "    ax.set_ylabel(label, fontsize=11)\n",
    "    ax.set_title(f'{label} vs Predictability', fontsize=12)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('hyperparameter_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nVisualization saved: hyperparameter_analysis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Interpretation & Discussion\n",
    "\n",
    "### Key Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate interpretive summary\n",
    "print(\"=\"*80)\n",
    "print(\"KEY FINDINGS: SATELLITE EMBEDDINGS FOR SDG PREDICTION IN BOLIVIA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Top 3 most predictable SDGs\n",
    "top_3 = df_results.nsmallest(3, 'rank')\n",
    "print(\"\\n1. MOST PREDICTABLE SDGs (highest R²):\")\n",
    "print(\"-\" * 60)\n",
    "for _, row in top_3.iterrows():\n",
    "    print(f\"   {row['rank']}. {row['description']}\")\n",
    "    print(f\"      R² = {row['r2_mean']:.4f} (95% CI: {row['r2_ci_lower']:.4f} - {row['r2_ci_upper']:.4f})\")\n",
    "    print(f\"      MAE = {row['mae_mean']:.2f}\")\n",
    "\n",
    "# Bottom 3 least predictable SDGs\n",
    "bottom_3 = df_results.nlargest(3, 'rank')\n",
    "print(\"\\n2. LEAST PREDICTABLE SDGs (lowest R²):\")\n",
    "print(\"-\" * 60)\n",
    "for _, row in bottom_3.iterrows():\n",
    "    print(f\"   {row['rank']}. {row['description']}\")\n",
    "    print(f\"      R² = {row['r2_mean']:.4f} (95% CI: {row['r2_ci_lower']:.4f} - {row['r2_ci_upper']:.4f})\")\n",
    "    print(f\"      MAE = {row['mae_mean']:.2f}\")\n",
    "\n",
    "# Category summary\n",
    "print(\"\\n3. PREDICTABILITY BY CATEGORY:\")\n",
    "print(\"-\" * 60)\n",
    "cat_means = df_results.groupby('category')['r2_mean'].mean().sort_values(ascending=False)\n",
    "for cat, r2 in cat_means.items():\n",
    "    n_sdgs = (df_results['category'] == cat).sum()\n",
    "    print(f\"   {cat:<15} | Mean R² = {r2:.4f} | ({n_sdgs} SDGs)\")\n",
    "\n",
    "# Feature insights\n",
    "print(\"\\n4. FEATURE IMPORTANCE INSIGHTS:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"   - Top 3 features: {', '.join(aggregate_importance.head(3).index.tolist())}\")\n",
    "print(f\"   - Features for 80% importance: {n_features_80}/64 ({n_features_80/64*100:.1f}%)\")\n",
    "\n",
    "# Statistical summary\n",
    "print(\"\\n5. OVERALL STATISTICS:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"   - Mean R² across all SDGs: {df_results['r2_mean'].mean():.4f}\")\n",
    "print(f\"   - Median R²: {df_results['r2_mean'].median():.4f}\")\n",
    "print(f\"   - R² range: [{df_results['r2_mean'].min():.4f}, {df_results['r2_mean'].max():.4f}]\")\n",
    "print(f\"   - SDGs with R² > 0.3: {(df_results['r2_mean'] > 0.3).sum()}/{len(df_results)}\")\n",
    "print(f\"   - SDGs with R² > 0.2: {(df_results['r2_mean'] > 0.2).sum()}/{len(df_results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation Framework\n",
    "\n",
    "**Why are some SDGs more predictable than others?**\n",
    "\n",
    "1. **High predictability SDGs** (R² > 0.35):\n",
    "   - Likely related to **visible infrastructure** (buildings, roads, electricity)\n",
    "   - Correlate with **land use patterns** (urban vs rural)\n",
    "   - Reflect **physical development** captured by satellite imagery\n",
    "\n",
    "2. **Low predictability SDGs** (R² < 0.15):\n",
    "   - Related to **social outcomes** (education quality, gender equality)\n",
    "   - Depend on **institutional factors** not visible from space\n",
    "   - Require **survey data** not captured by remote sensing\n",
    "\n",
    "**Policy Implications:**\n",
    "- Satellite data can help **target interventions** for infrastructure-related SDGs\n",
    "- For social SDGs, traditional surveys remain essential\n",
    "- Combining satellite and survey data may improve predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Export Results\n",
    "\n",
    "Let's save all results for further analysis and reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export 1: Main results table\n",
    "export_cols = ['rank', 'variable', 'description', 'category', 'n_samples',\n",
    "               'r2_mean', 'r2_std', 'r2_ci_lower', 'r2_ci_upper',\n",
    "               'rmse_mean', 'rmse_std', 'mae_mean', 'mae_std', 'predictability']\n",
    "df_results[export_cols].to_csv('all_sdg_results.csv', index=False)\n",
    "print(\"Saved: all_sdg_results.csv\")\n",
    "\n",
    "# Export 2: Feature importance matrix\n",
    "feature_importance_df.to_csv('all_sdg_feature_importance.csv')\n",
    "print(\"Saved: all_sdg_feature_importance.csv\")\n",
    "\n",
    "# Export 3: Aggregate feature importance\n",
    "aggregate_importance.to_frame('importance').to_csv('aggregate_feature_importance.csv')\n",
    "print(\"Saved: aggregate_feature_importance.csv\")\n",
    "\n",
    "# Export 4: Best hyperparameters\n",
    "df_hyperparams.to_csv('best_hyperparameters.csv', index=False)\n",
    "print(\"Saved: best_hyperparameters.csv\")\n",
    "\n",
    "# Export 5: Summary as JSON\n",
    "summary_json = {\n",
    "    'methodology': {\n",
    "        'algorithm': 'XGBoost',\n",
    "        'gpu_accelerated': GPU_AVAILABLE,\n",
    "        'outer_folds': N_OUTER_FOLDS,\n",
    "        'inner_folds': N_INNER_FOLDS,\n",
    "        'optuna_trials': N_TRIALS,\n",
    "        'n_features': 64,\n",
    "        'n_targets': len(TARGET_VARIABLES),\n",
    "        'total_execution_time_minutes': total_time / 60\n",
    "    },\n",
    "    'overall_statistics': {\n",
    "        'mean_r2': float(df_results['r2_mean'].mean()),\n",
    "        'median_r2': float(df_results['r2_mean'].median()),\n",
    "        'min_r2': float(df_results['r2_mean'].min()),\n",
    "        'max_r2': float(df_results['r2_mean'].max()),\n",
    "        'sdgs_above_0.3': int((df_results['r2_mean'] > 0.3).sum()),\n",
    "        'sdgs_above_0.2': int((df_results['r2_mean'] > 0.2).sum()),\n",
    "    },\n",
    "    'top_features': aggregate_importance.head(10).to_dict(),\n",
    "    'features_for_80pct': int(n_features_80),\n",
    "}\n",
    "\n",
    "with open('analysis_summary.json', 'w') as f:\n",
    "    json.dump(summary_json, f, indent=2)\n",
    "print(\"Saved: analysis_summary.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate markdown summary table for publications\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PUBLICATION-READY SUMMARY TABLE (Markdown)\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "markdown_table = \"| Rank | SDG Indicator | Category | R² (95% CI) | MAE | Predictability |\\n\"\n",
    "markdown_table += \"|------|---------------|----------|-------------|-----|----------------|\\n\"\n",
    "\n",
    "for _, row in df_results.iterrows():\n",
    "    ci_str = f\"{row['r2_mean']:.3f} ({row['r2_ci_lower']:.3f}-{row['r2_ci_upper']:.3f})\"\n",
    "    markdown_table += f\"| {row['rank']} | {row['description']} | {row['category']} | {ci_str} | {row['mae_mean']:.2f} | {row['predictability']} |\\n\"\n",
    "\n",
    "print(markdown_table)\n",
    "\n",
    "# Save to file\n",
    "with open('summary_table.md', 'w') as f:\n",
    "    f.write(\"# Comparative SDG Predictability from Satellite Embeddings\\n\\n\")\n",
    "    f.write(\"## Results Summary\\n\\n\")\n",
    "    f.write(markdown_table)\n",
    "    f.write(\"\\n\\n*Generated using XGBoost with nested cross-validation and Optuna hyperparameter tuning.*\\n\")\n",
    "\n",
    "print(\"\\nSaved: summary_table.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Student Exercises\n",
    "\n",
    "Try these exercises to deepen your understanding:\n",
    "\n",
    "### Exercise 1: Model Comparison\n",
    "Modify the code to also run **LightGBM** and compare its performance with XGBoost. Which algorithm performs better for which SDGs?\n",
    "\n",
    "### Exercise 2: SHAP Analysis\n",
    "Install the `shap` library and compute SHAP values for one of the top-performing SDGs. Which features contribute most to individual predictions?\n",
    "\n",
    "```python\n",
    "import shap\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "shap.summary_plot(shap_values, X_test, feature_names=FEATURE_COLS)\n",
    "```\n",
    "\n",
    "### Exercise 3: Spatial Cross-Validation\n",
    "The current analysis uses random splits. Implement **spatial cross-validation** using geographic coordinates to avoid spatial leakage. Does performance change?\n",
    "\n",
    "### Exercise 4: Feature Engineering\n",
    "Create new features by:\n",
    "- Adding polynomial interactions between top features\n",
    "- Including night-time lights data\n",
    "- Adding geographic coordinates (latitude, longitude)\n",
    "\n",
    "Does performance improve?\n",
    "\n",
    "### Exercise 5: Prediction Maps\n",
    "For the best-performing SDG, create a choropleth map showing:\n",
    "- Actual values\n",
    "- Predicted values\n",
    "- Prediction errors\n",
    "\n",
    "Where does the model perform well vs poorly spatially?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. References\n",
    "\n",
    "### Methodological References\n",
    "\n",
    "- Chen, T., & Guestrin, C. (2016). XGBoost: A Scalable Tree Boosting System. *KDD '16*.\n",
    "- Akiba, T., et al. (2019). Optuna: A Next-generation Hyperparameter Optimization Framework. *KDD '19*.\n",
    "- Varma, S., & Simon, R. (2006). Bias in error estimation when using cross-validation for model selection. *BMC Bioinformatics*.\n",
    "\n",
    "### Domain References\n",
    "\n",
    "- Jean, N., et al. (2016). Combining satellite imagery and machine learning to predict poverty. *Science*.\n",
    "- Yeh, C., et al. (2020). Using publicly available satellite imagery and deep learning to understand economic well-being in Africa. *Nature Communications*.\n",
    "- Andersen, L. E., et al. (2020). Atlas municipal de los Objetivos de Desarrollo Sostenible en Bolivia 2020.\n",
    "\n",
    "### Citation\n",
    "\n",
    "If you use this analysis, please cite:\n",
    "\n",
    "```\n",
    "Mendez, C., Gonzales, E., Leoni, P., Andersen, L., Peralta, H. (2026).\n",
    "DS4Bolivia: A Data Science Repository to Study GeoSpatial Development in Bolivia\n",
    "[Data set]. GitHub. https://github.com/quarcs-lab/ds4bolivia\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nFiles generated:\")\n",
    "print(\"  1. all_sdgs_comparison.png - Main comparison visualization\")\n",
    "print(\"  2. feature_importance_analysis.png - Feature importance heatmap\")\n",
    "print(\"  3. hyperparameter_analysis.png - Hyperparameter patterns\")\n",
    "print(\"  4. all_sdg_results.csv - Complete results table\")\n",
    "print(\"  5. all_sdg_feature_importance.csv - Feature importance matrix\")\n",
    "print(\"  6. aggregate_feature_importance.csv - Averaged feature importance\")\n",
    "print(\"  7. best_hyperparameters.csv - Optimal hyperparameters per SDG\")\n",
    "print(\"  8. analysis_summary.json - Summary statistics\")\n",
    "print(\"  9. summary_table.md - Publication-ready markdown table\")\n",
    "print(\"\\nThank you for using DS4Bolivia!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}