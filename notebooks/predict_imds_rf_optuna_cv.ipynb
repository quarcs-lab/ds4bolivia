{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting IMDS with Optuna and Nested Cross-Validation\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/quarcs-lab/ds4bolivia/blob/master/notebooks/predict_imds_rf_optuna_cv.ipynb)\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook implements **nested cross-validation** (also called double cross-validation) for hyperparameter tuning and model evaluation. This is the gold standard for rigorous model assessment when dataset size is limited.\n",
    "\n",
    "### What Makes This Different?\n",
    "\n",
    "| Approach | Train-Test Split | Nested CV |\n",
    "|----------|------------------|----------|\n",
    "| Test evaluation | Single split (20%) | All data, K times |\n",
    "| Performance estimate | One number | Distribution of scores |\n",
    "| Variance estimate | None | Standard deviation across folds |\n",
    "| Data efficiency | 80% for training | 100% used for both |\n",
    "| Risk of lucky split | High | Eliminated |\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will understand:\n",
    "\n",
    "1. **Why nested CV is important** for unbiased performance estimation\n",
    "2. **The structure of nested loops** (outer for evaluation, inner for tuning)\n",
    "3. **How to implement nested CV with Optuna** efficiently\n",
    "4. **Interpreting results** from multiple folds\n",
    "5. **When to use nested CV** vs. simple train-test splits\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Problem with Simple Train-Test Splits\n",
    "\n",
    "When we use a single train-test split for hyperparameter tuning:\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────┬─────────────┐\n",
    "│         Training Set (80%)              │  Test (20%) │\n",
    "│  ┌─────────────────────────────────┐    │             │\n",
    "│  │ Optuna tunes hyperparameters    │    │  Final      │\n",
    "│  │ using CV on this portion        │    │  Eval       │\n",
    "│  └─────────────────────────────────┘    │             │\n",
    "└─────────────────────────────────────────┴─────────────┘\n",
    "```\n",
    "\n",
    "**Problems:**\n",
    "1. The test set might be \"lucky\" (easy) or \"unlucky\" (hard)\n",
    "2. We only get ONE performance number - no sense of variance\n",
    "3. 20% of data is never used for training\n",
    "\n",
    "## The Solution: Nested Cross-Validation\n",
    "\n",
    "```\n",
    "┌────────────────────────────────────────────────────────────────┐\n",
    "│                    OUTER LOOP (5 folds)                        │\n",
    "│  Provides unbiased performance estimates                       │\n",
    "│                                                                │\n",
    "│  Fold 1: [████████████████████████████████████████] [TEST]     │\n",
    "│  Fold 2: [████████████] [TEST] [██████████████████████████]    │\n",
    "│  Fold 3: [████████████████████] [TEST] [██████████████████]    │\n",
    "│  Fold 4: [██████████████████████████████] [TEST] [████████]    │\n",
    "│  Fold 5: [TEST] [████████████████████████████████████████]     │\n",
    "│                                                                │\n",
    "│  For each outer fold:                                          │\n",
    "│  ┌──────────────────────────────────────────────────────────┐  │\n",
    "│  │              INNER LOOP (5 folds within training)        │  │\n",
    "│  │  Optuna uses this for hyperparameter optimization        │  │\n",
    "│  │                                                          │  │\n",
    "│  │  Inner fold 1: [████████████████████████] [VAL]          │  │\n",
    "│  │  Inner fold 2: [████████] [VAL] [████████████████]       │  │\n",
    "│  │  ...                                                     │  │\n",
    "│  └──────────────────────────────────────────────────────────┘  │\n",
    "└────────────────────────────────────────────────────────────────┘\n",
    "\n",
    "Result: 5 independent test scores → Mean ± Std\n",
    "```\n",
    "\n",
    "**Benefits:**\n",
    "1. Every data point is used for testing exactly once\n",
    "2. We get 5 independent performance estimates\n",
    "3. We can calculate confidence intervals\n",
    "4. More reliable estimate of real-world performance\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "First, we install Optuna and import all required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# INSTALL OPTUNA\n",
    "# =============================================================================\n",
    "# Optuna is not pre-installed in Google Colab, so we install it first.\n",
    "# The -q flag suppresses verbose output for cleaner notebooks.\n",
    "\n",
    "!pip install -q optuna\n",
    "\n",
    "print(\"Optuna installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# IMPORT LIBRARIES\n",
    "# =============================================================================\n",
    "\n",
    "# Data manipulation and numerical computing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning - scikit-learn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import (\n",
    "    cross_val_score,     # Simple cross-validation\n",
    "    KFold,               # K-Fold splitter\n",
    "    cross_val_predict    # Get predictions from CV\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    r2_score\n",
    ")\n",
    "\n",
    "# Hyperparameter optimization\n",
    "import optuna\n",
    "from optuna.visualization import (\n",
    "    plot_optimization_history,\n",
    "    plot_param_importances,\n",
    "    plot_slice\n",
    ")\n",
    "\n",
    "# Progress tracking\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Reduce Optuna verbosity\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# =============================================================================\n",
    "# REPRODUCIBILITY\n",
    "# =============================================================================\n",
    "# Setting random seeds ensures reproducible results.\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(f\"Optuna version: {optuna.__version__}\")\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preparation\n",
    "\n",
    "We load the same datasets as in previous notebooks:\n",
    "- **IMDS**: Municipal Sustainable Development Index (target)\n",
    "- **Satellite Embeddings**: 64-dimensional features from Google Earth Engine\n",
    "- **Region Names**: Municipality and department names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATA LOADING\n",
    "# =============================================================================\n",
    "\n",
    "REPO_URL = \"https://raw.githubusercontent.com/quarcs-lab/ds4bolivia/master\"\n",
    "\n",
    "# Define URLs\n",
    "url_sdg = f\"{REPO_URL}/sdg/sdg.csv\"\n",
    "url_emb = f\"{REPO_URL}/satelliteEmbeddings/satelliteEmbeddings2017.csv\"\n",
    "url_names = f\"{REPO_URL}/regionNames/regionNames.csv\"\n",
    "\n",
    "# Load datasets\n",
    "print(\"Loading datasets from GitHub...\")\n",
    "df_sdg = pd.read_csv(url_sdg)\n",
    "df_embeddings = pd.read_csv(url_emb)\n",
    "df_names = pd.read_csv(url_names)\n",
    "\n",
    "print(f\"✓ SDG data: {len(df_sdg)} municipalities\")\n",
    "print(f\"✓ Satellite embeddings: {len(df_embeddings)} municipalities\")\n",
    "print(f\"✓ Region names: {len(df_names)} municipalities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATA MERGING AND PREPARATION\n",
    "# =============================================================================\n",
    "\n",
    "# Merge datasets using asdf_id as the key\n",
    "df_merged = df_sdg[['asdf_id', 'imds']].merge(\n",
    "    df_embeddings, on='asdf_id', how='inner'\n",
    ")\n",
    "df_merged = df_merged.merge(\n",
    "    df_names[['asdf_id', 'mun', 'dep']], on='asdf_id', how='left'\n",
    ")\n",
    "\n",
    "# Remove missing values\n",
    "df_clean = df_merged.dropna(subset=['imds']).copy()\n",
    "\n",
    "# Prepare features and target\n",
    "embedding_cols = [f'A{str(i).zfill(2)}' for i in range(64)]\n",
    "X = df_clean[embedding_cols].values\n",
    "y = df_clean['imds'].values\n",
    "\n",
    "print(f\"\\nDataset prepared:\")\n",
    "print(f\"  Samples: {X.shape[0]}\")\n",
    "print(f\"  Features: {X.shape[1]}\")\n",
    "print(f\"  Target (IMDS): range [{y.min():.2f}, {y.max():.2f}], mean {y.mean():.2f} ± {y.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Understanding Nested Cross-Validation\n",
    "\n",
    "### The Two Loops\n",
    "\n",
    "**Outer Loop (Evaluation)**:\n",
    "- Splits data into training and test folds\n",
    "- Each fold's test set is used ONLY for final evaluation\n",
    "- Provides unbiased performance estimates\n",
    "\n",
    "**Inner Loop (Hyperparameter Tuning)**:\n",
    "- Runs WITHIN each outer training fold\n",
    "- Optuna uses this for hyperparameter optimization\n",
    "- Best parameters are selected for each outer fold independently\n",
    "\n",
    "### Key Insight: Different Parameters Per Fold\n",
    "\n",
    "In nested CV, each outer fold may find DIFFERENT optimal hyperparameters. This is expected and actually provides useful information about parameter stability.\n",
    "\n",
    "```\n",
    "Outer Fold 1: Best params → {n_estimators: 200, max_depth: 15, ...}\n",
    "Outer Fold 2: Best params → {n_estimators: 150, max_depth: 20, ...}\n",
    "Outer Fold 3: Best params → {n_estimators: 250, max_depth: 12, ...}\n",
    "...\n",
    "```\n",
    "\n",
    "If parameters vary wildly across folds, it suggests the model is unstable or the dataset is too small.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configuration Parameters\n",
    "\n",
    "We define all configuration parameters in one place for easy modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# NESTED CV CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# Outer loop: For unbiased performance estimation\n",
    "OUTER_FOLDS = 5      # Number of outer CV folds\n",
    "\n",
    "# Inner loop: For hyperparameter tuning within Optuna\n",
    "INNER_FOLDS = 5      # Number of inner CV folds (used by Optuna)\n",
    "\n",
    "# Optuna configuration\n",
    "N_TRIALS = 50        # Number of Optuna trials per outer fold\n",
    "                     # (Reduced from 100 since we run 5 times)\n",
    "\n",
    "print(\"NESTED CROSS-VALIDATION CONFIGURATION\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nOuter CV folds: {OUTER_FOLDS}\")\n",
    "print(f\"Inner CV folds: {INNER_FOLDS}\")\n",
    "print(f\"Optuna trials per outer fold: {N_TRIALS}\")\n",
    "print(f\"\\nTotal Optuna studies: {OUTER_FOLDS}\")\n",
    "print(f\"Total trials: {OUTER_FOLDS * N_TRIALS}\")\n",
    "print(f\"Total models trained: {OUTER_FOLDS * N_TRIALS * INNER_FOLDS}\")\n",
    "print(f\"\\nNote: This may take 10-20 minutes depending on hardware.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Defining the Objective Function\n",
    "\n",
    "The objective function for Optuna remains similar, but now it will be called within each outer fold's training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# OBJECTIVE FUNCTION FACTORY\n",
    "# =============================================================================\n",
    "# We create a function that RETURNS the objective function.\n",
    "# This allows us to pass the current fold's training data to Optuna.\n",
    "\n",
    "def create_objective(X_train_fold, y_train_fold, inner_cv):\n",
    "    \"\"\"\n",
    "    Factory function that creates an Optuna objective for a specific fold.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_train_fold : array\n",
    "        Training features for this outer fold\n",
    "    y_train_fold : array\n",
    "        Training targets for this outer fold\n",
    "    inner_cv : KFold\n",
    "        Inner cross-validation splitter\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    function\n",
    "        Objective function for Optuna\n",
    "    \"\"\"\n",
    "    \n",
    "    def objective(trial):\n",
    "        # -----------------------------------------------------------------\n",
    "        # Sample hyperparameters from search space\n",
    "        # -----------------------------------------------------------------\n",
    "        \n",
    "        # Number of trees\n",
    "        n_estimators = trial.suggest_int('n_estimators', 50, 400, step=50)\n",
    "        \n",
    "        # Maximum tree depth\n",
    "        max_depth = trial.suggest_int('max_depth', 5, 40)\n",
    "        \n",
    "        # Minimum samples to split a node\n",
    "        min_samples_split = trial.suggest_int('min_samples_split', 2, 15)\n",
    "        \n",
    "        # Minimum samples at leaf nodes\n",
    "        min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 8)\n",
    "        \n",
    "        # Features to consider per split\n",
    "        max_features = trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\n",
    "        \n",
    "        # -----------------------------------------------------------------\n",
    "        # Create and evaluate model\n",
    "        # -----------------------------------------------------------------\n",
    "        \n",
    "        model = RandomForestRegressor(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            max_features=max_features,\n",
    "            random_state=RANDOM_STATE,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        # Inner cross-validation on THIS fold's training data\n",
    "        cv_scores = cross_val_score(\n",
    "            model, \n",
    "            X_train_fold, \n",
    "            y_train_fold, \n",
    "            cv=inner_cv, \n",
    "            scoring='r2'\n",
    "        )\n",
    "        \n",
    "        return cv_scores.mean()\n",
    "    \n",
    "    return objective\n",
    "\n",
    "print(\"Objective function factory defined.\")\n",
    "print(\"\\nSearch space:\")\n",
    "print(\"  n_estimators:      [50, 400] step=50\")\n",
    "print(\"  max_depth:         [5, 40]\")\n",
    "print(\"  min_samples_split: [2, 15]\")\n",
    "print(\"  min_samples_leaf:  [1, 8]\")\n",
    "print(\"  max_features:      ['sqrt', 'log2', None]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Running Nested Cross-Validation\n",
    "\n",
    "Now we implement the full nested CV procedure:\n",
    "\n",
    "1. **For each outer fold**:\n",
    "   - Split data into training (80%) and test (20%)\n",
    "   - Run Optuna on the training portion to find best hyperparameters\n",
    "   - Train final model with best parameters on full training portion\n",
    "   - Evaluate on the held-out test portion\n",
    "   - Store results\n",
    "\n",
    "2. **After all folds**:\n",
    "   - Calculate mean and std of performance metrics\n",
    "   - Analyze parameter stability across folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# NESTED CROSS-VALIDATION MAIN LOOP\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"STARTING NESTED CROSS-VALIDATION WITH OPTUNA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Initialize storage for results\n",
    "outer_results = []          # Performance metrics for each outer fold\n",
    "best_params_all_folds = []  # Best hyperparameters from each fold\n",
    "all_predictions = np.zeros_like(y)  # Store predictions for all samples\n",
    "all_actuals = np.zeros_like(y)\n",
    "fold_indices = np.zeros_like(y, dtype=int)  # Track which fold each sample was in\n",
    "\n",
    "# Create outer CV splitter\n",
    "outer_cv = KFold(n_splits=OUTER_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# Create inner CV splitter (will be reused)\n",
    "inner_cv = KFold(n_splits=INNER_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "print(f\"\\nStarting {OUTER_FOLDS}-fold outer cross-validation...\\n\")\n",
    "\n",
    "# ----- OUTER LOOP: Iterate through each outer fold -----\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(outer_cv.split(X), 1):\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"OUTER FOLD {fold_idx}/{OUTER_FOLDS}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Training samples: {len(train_idx)} | Test samples: {len(test_idx)}\")\n",
    "    \n",
    "    # Split data for this outer fold\n",
    "    X_train_fold, X_test_fold = X[train_idx], X[test_idx]\n",
    "    y_train_fold, y_test_fold = y[train_idx], y[test_idx]\n",
    "    \n",
    "    # ----- INNER LOOP: Optuna hyperparameter optimization -----\n",
    "    print(f\"\\n  Running Optuna optimization ({N_TRIALS} trials)...\")\n",
    "    \n",
    "    # Create objective function for this fold's training data\n",
    "    objective = create_objective(X_train_fold, y_train_fold, inner_cv)\n",
    "    \n",
    "    # Create and run Optuna study\n",
    "    study = optuna.create_study(\n",
    "        direction='maximize',\n",
    "        sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE + fold_idx)\n",
    "    )\n",
    "    \n",
    "    study.optimize(objective, n_trials=N_TRIALS, show_progress_bar=True)\n",
    "    \n",
    "    # Get best parameters for this fold\n",
    "    best_params = study.best_params\n",
    "    best_cv_score = study.best_value\n",
    "    best_params_all_folds.append(best_params)\n",
    "    \n",
    "    print(f\"\\n  Best inner CV R²: {best_cv_score:.4f}\")\n",
    "    print(f\"  Best parameters: {best_params}\")\n",
    "    \n",
    "    # ----- Train final model with best parameters -----\n",
    "    print(f\"\\n  Training final model for this fold...\")\n",
    "    \n",
    "    final_model = RandomForestRegressor(\n",
    "        **best_params,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    final_model.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # ----- Evaluate on held-out test fold -----\n",
    "    y_pred_fold = final_model.predict(X_test_fold)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    fold_r2 = r2_score(y_test_fold, y_pred_fold)\n",
    "    fold_rmse = np.sqrt(mean_squared_error(y_test_fold, y_pred_fold))\n",
    "    fold_mae = mean_absolute_error(y_test_fold, y_pred_fold)\n",
    "    \n",
    "    # Store results\n",
    "    outer_results.append({\n",
    "        'fold': fold_idx,\n",
    "        'r2': fold_r2,\n",
    "        'rmse': fold_rmse,\n",
    "        'mae': fold_mae,\n",
    "        'best_cv_score': best_cv_score,\n",
    "        'n_test_samples': len(test_idx)\n",
    "    })\n",
    "    \n",
    "    # Store predictions for later analysis\n",
    "    all_predictions[test_idx] = y_pred_fold\n",
    "    all_actuals[test_idx] = y_test_fold\n",
    "    fold_indices[test_idx] = fold_idx\n",
    "    \n",
    "    print(f\"\\n  FOLD {fold_idx} TEST RESULTS:\")\n",
    "    print(f\"    R² Score: {fold_r2:.4f}\")\n",
    "    print(f\"    RMSE:     {fold_rmse:.4f}\")\n",
    "    print(f\"    MAE:      {fold_mae:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"NESTED CROSS-VALIDATION COMPLETE!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Aggregating Results Across Folds\n",
    "\n",
    "Now we combine results from all outer folds to get our final performance estimates with confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CREATE RESULTS DATAFRAME\n",
    "# =============================================================================\n",
    "\n",
    "results_df = pd.DataFrame(outer_results)\n",
    "\n",
    "print(\"RESULTS FOR EACH OUTER FOLD\")\n",
    "print(\"=\"*60)\n",
    "print(results_df.to_string(index=False))\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# AGGREGATE PERFORMANCE METRICS\n",
    "# =============================================================================\n",
    "\n",
    "# Calculate mean and std for each metric\n",
    "mean_r2 = results_df['r2'].mean()\n",
    "std_r2 = results_df['r2'].std()\n",
    "\n",
    "mean_rmse = results_df['rmse'].mean()\n",
    "std_rmse = results_df['rmse'].std()\n",
    "\n",
    "mean_mae = results_df['mae'].mean()\n",
    "std_mae = results_df['mae'].std()\n",
    "\n",
    "print(\"\\nAGGREGATED PERFORMANCE (NESTED CV)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n{'Metric':<15} {'Mean':<15} {'Std':<15} {'95% CI'}\")\n",
    "print(\"-\"*60)\n",
    "print(f\"{'R² Score':<15} {mean_r2:<15.4f} {std_r2:<15.4f} [{mean_r2-1.96*std_r2:.4f}, {mean_r2+1.96*std_r2:.4f}]\")\n",
    "print(f\"{'RMSE':<15} {mean_rmse:<15.4f} {std_rmse:<15.4f} [{mean_rmse-1.96*std_rmse:.4f}, {mean_rmse+1.96*std_rmse:.4f}]\")\n",
    "print(f\"{'MAE':<15} {mean_mae:<15.4f} {std_mae:<15.4f} [{mean_mae-1.96*std_mae:.4f}, {mean_mae+1.96*std_mae:.4f}]\")\n",
    "print(\"-\"*60)\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"  The model explains {mean_r2*100:.1f}% ± {std_r2*100:.1f}% of IMDS variance.\")\n",
    "print(f\"  Average prediction error: {mean_mae:.2f} ± {std_mae:.2f} IMDS points.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VISUALIZE FOLD-BY-FOLD PERFORMANCE\n",
    "# =============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "\n",
    "# R² across folds\n",
    "ax1 = axes[0]\n",
    "ax1.bar(results_df['fold'], results_df['r2'], color='steelblue', edgecolor='black')\n",
    "ax1.axhline(y=mean_r2, color='red', linestyle='--', lw=2, label=f'Mean: {mean_r2:.4f}')\n",
    "ax1.fill_between([0.5, OUTER_FOLDS+0.5], mean_r2-std_r2, mean_r2+std_r2, \n",
    "                 alpha=0.2, color='red', label=f'±1 Std: {std_r2:.4f}')\n",
    "ax1.set_xlabel('Outer Fold', fontsize=11)\n",
    "ax1.set_ylabel('R² Score', fontsize=11)\n",
    "ax1.set_title('R² Score by Fold', fontsize=12, fontweight='bold')\n",
    "ax1.legend(loc='lower right')\n",
    "ax1.set_xticks(results_df['fold'])\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# RMSE across folds\n",
    "ax2 = axes[1]\n",
    "ax2.bar(results_df['fold'], results_df['rmse'], color='coral', edgecolor='black')\n",
    "ax2.axhline(y=mean_rmse, color='red', linestyle='--', lw=2, label=f'Mean: {mean_rmse:.2f}')\n",
    "ax2.set_xlabel('Outer Fold', fontsize=11)\n",
    "ax2.set_ylabel('RMSE', fontsize=11)\n",
    "ax2.set_title('RMSE by Fold', fontsize=12, fontweight='bold')\n",
    "ax2.legend(loc='upper right')\n",
    "ax2.set_xticks(results_df['fold'])\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# MAE across folds\n",
    "ax3 = axes[2]\n",
    "ax3.bar(results_df['fold'], results_df['mae'], color='mediumseagreen', edgecolor='black')\n",
    "ax3.axhline(y=mean_mae, color='red', linestyle='--', lw=2, label=f'Mean: {mean_mae:.2f}')\n",
    "ax3.set_xlabel('Outer Fold', fontsize=11)\n",
    "ax3.set_ylabel('MAE', fontsize=11)\n",
    "ax3.set_title('MAE by Fold', fontsize=12, fontweight='bold')\n",
    "ax3.legend(loc='upper right')\n",
    "ax3.set_xticks(results_df['fold'])\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Analyzing Hyperparameter Stability\n",
    "\n",
    "An important aspect of nested CV is examining whether the optimal hyperparameters are consistent across folds. Large variations suggest model instability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HYPERPARAMETER STABILITY ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "# Create DataFrame of best parameters from each fold\n",
    "params_df = pd.DataFrame(best_params_all_folds)\n",
    "params_df.index = [f'Fold {i+1}' for i in range(OUTER_FOLDS)]\n",
    "\n",
    "print(\"BEST HYPERPARAMETERS BY FOLD\")\n",
    "print(\"=\"*70)\n",
    "print(params_df.to_string())\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PARAMETER VARIATION STATISTICS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nHYPERPARAMETER VARIATION ACROSS FOLDS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# For numerical parameters, show mean and std\n",
    "numerical_params = ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf']\n",
    "\n",
    "print(f\"\\n{'Parameter':<20} {'Mean':<12} {'Std':<12} {'Min':<10} {'Max':<10}\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "for param in numerical_params:\n",
    "    values = params_df[param]\n",
    "    print(f\"{param:<20} {values.mean():<12.1f} {values.std():<12.1f} {values.min():<10} {values.max():<10}\")\n",
    "\n",
    "# For categorical parameter, show mode\n",
    "print(f\"\\n{'max_features':<20} Mode: {params_df['max_features'].mode().values[0]}\")\n",
    "print(f\"                     Distribution: {params_df['max_features'].value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VISUALIZE PARAMETER DISTRIBUTIONS\n",
    "# =============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "for ax, param in zip(axes.flatten(), numerical_params):\n",
    "    values = params_df[param]\n",
    "    ax.bar(range(1, OUTER_FOLDS+1), values, color='steelblue', edgecolor='black')\n",
    "    ax.axhline(y=values.mean(), color='red', linestyle='--', lw=2, \n",
    "               label=f'Mean: {values.mean():.1f}')\n",
    "    ax.set_xlabel('Outer Fold', fontsize=10)\n",
    "    ax.set_ylabel(param, fontsize=10)\n",
    "    ax.set_title(f'{param} Across Folds', fontsize=11, fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.set_xticks(range(1, OUTER_FOLDS+1))\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Overall Prediction Analysis\n",
    "\n",
    "Since every sample was in the test set exactly once, we can analyze predictions for the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# OVERALL PREDICTION PERFORMANCE\n",
    "# =============================================================================\n",
    "\n",
    "# Calculate overall metrics (combining all fold predictions)\n",
    "overall_r2 = r2_score(all_actuals, all_predictions)\n",
    "overall_rmse = np.sqrt(mean_squared_error(all_actuals, all_predictions))\n",
    "overall_mae = mean_absolute_error(all_actuals, all_predictions)\n",
    "\n",
    "print(\"OVERALL PERFORMANCE (All Predictions Combined)\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nR² Score: {overall_r2:.4f}\")\n",
    "print(f\"RMSE:     {overall_rmse:.4f}\")\n",
    "print(f\"MAE:      {overall_mae:.4f}\")\n",
    "print(f\"\\nNote: This combines predictions where each sample was\")\n",
    "print(f\"      in the test set of exactly one fold.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PREDICTION VISUALIZATIONS\n",
    "# =============================================================================\n",
    "\n",
    "# Calculate errors\n",
    "errors = all_actuals - all_predictions\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Plot 1: Actual vs Predicted (colored by fold)\n",
    "ax1 = axes[0]\n",
    "scatter = ax1.scatter(all_actuals, all_predictions, c=fold_indices, \n",
    "                      cmap='tab10', alpha=0.6, edgecolors='k', linewidth=0.3)\n",
    "ax1.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2, label='Perfect')\n",
    "ax1.set_xlabel('Actual IMDS', fontsize=11)\n",
    "ax1.set_ylabel('Predicted IMDS', fontsize=11)\n",
    "ax1.set_title(f'Actual vs Predicted (All Folds)\\nR² = {overall_r2:.4f}', \n",
    "              fontsize=12, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "cbar = plt.colorbar(scatter, ax=ax1)\n",
    "cbar.set_label('Fold')\n",
    "\n",
    "# Plot 2: Residuals\n",
    "ax2 = axes[1]\n",
    "ax2.scatter(all_predictions, errors, alpha=0.5, edgecolors='k', linewidth=0.3)\n",
    "ax2.axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "ax2.set_xlabel('Predicted IMDS', fontsize=11)\n",
    "ax2.set_ylabel('Residuals', fontsize=11)\n",
    "ax2.set_title('Residual Plot', fontsize=12, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Error Distribution\n",
    "ax3 = axes[2]\n",
    "ax3.hist(errors, bins=25, edgecolor='black', alpha=0.7)\n",
    "ax3.axvline(x=0, color='r', linestyle='--', lw=2)\n",
    "ax3.axvline(x=errors.mean(), color='blue', linestyle='-', lw=2,\n",
    "            label=f'Mean: {errors.mean():.2f}')\n",
    "ax3.set_xlabel('Prediction Error', fontsize=11)\n",
    "ax3.set_ylabel('Frequency', fontsize=11)\n",
    "ax3.set_title(f'Error Distribution\\nMAE = {overall_mae:.2f}', \n",
    "              fontsize=12, fontweight='bold')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Municipality-Level Error Analysis\n",
    "\n",
    "Let's identify which municipalities are hardest/easiest to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CREATE FULL RESULTS DATAFRAME\n",
    "# =============================================================================\n",
    "\n",
    "# Add predictions and errors to the original dataframe\n",
    "df_results = df_clean.copy()\n",
    "df_results['imds_predicted'] = all_predictions\n",
    "df_results['error'] = errors\n",
    "df_results['abs_error'] = np.abs(errors)\n",
    "df_results['fold'] = fold_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TOP OVERPREDICTED MUNICIPALITIES\n",
    "# =============================================================================\n",
    "\n",
    "overpredicted = df_results.nsmallest(10, 'error')\n",
    "\n",
    "print(\"TOP 10 OVERPREDICTED MUNICIPALITIES\")\n",
    "print(\"(Model predicts HIGHER development than actual)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for _, row in overpredicted.iterrows():\n",
    "    print(f\"\\n  {row['mun']}, {row['dep']} (Fold {row['fold']})\")\n",
    "    print(f\"    Actual: {row['imds']:.2f} | Predicted: {row['imds_predicted']:.2f} | Error: {row['error']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TOP UNDERPREDICTED MUNICIPALITIES\n",
    "# =============================================================================\n",
    "\n",
    "underpredicted = df_results.nlargest(10, 'error')\n",
    "\n",
    "print(\"TOP 10 UNDERPREDICTED MUNICIPALITIES\")\n",
    "print(\"(Model predicts LOWER development than actual)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for _, row in underpredicted.iterrows():\n",
    "    print(f\"\\n  {row['mun']}, {row['dep']} (Fold {row['fold']})\")\n",
    "    print(f\"    Actual: {row['imds']:.2f} | Predicted: {row['imds_predicted']:.2f} | Error: {row['error']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ERROR BY DEPARTMENT\n",
    "# =============================================================================\n",
    "\n",
    "dept_analysis = df_results.groupby('dep').agg({\n",
    "    'error': ['mean', 'std'],\n",
    "    'abs_error': 'mean',\n",
    "    'mun': 'count'\n",
    "}).round(3)\n",
    "\n",
    "dept_analysis.columns = ['Mean Error', 'Std Error', 'Mean Abs Error', 'N Municipalities']\n",
    "dept_analysis = dept_analysis.sort_values('Mean Error')\n",
    "\n",
    "print(\"\\nPREDICTION ERRORS BY DEPARTMENT\")\n",
    "print(\"=\"*70)\n",
    "print(dept_analysis.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Final Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FINAL SUMMARY\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"FINAL SUMMARY: NESTED CV WITH OPTUNA HYPERPARAMETER TUNING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\"\"\n",
    "NESTED CROSS-VALIDATION CONFIGURATION:\n",
    "  • Outer folds: {OUTER_FOLDS}\n",
    "  • Inner folds: {INNER_FOLDS}\n",
    "  • Optuna trials per outer fold: {N_TRIALS}\n",
    "  • Total models trained: {OUTER_FOLDS * N_TRIALS * INNER_FOLDS}\n",
    "\n",
    "AGGREGATED PERFORMANCE METRICS:\n",
    "  • R² Score:  {mean_r2:.4f} ± {std_r2:.4f}  (95% CI: [{mean_r2-1.96*std_r2:.4f}, {mean_r2+1.96*std_r2:.4f}])\n",
    "  • RMSE:      {mean_rmse:.4f} ± {std_rmse:.4f}\n",
    "  • MAE:       {mean_mae:.4f} ± {std_mae:.4f}\n",
    "\n",
    "OVERALL PREDICTION PERFORMANCE:\n",
    "  • Combined R² (all folds): {overall_r2:.4f}\n",
    "  • Combined MAE: {overall_mae:.4f} IMDS points\n",
    "\n",
    "HYPERPARAMETER STABILITY:\n",
    "  • n_estimators: {params_df['n_estimators'].mean():.0f} ± {params_df['n_estimators'].std():.0f}\n",
    "  • max_depth: {params_df['max_depth'].mean():.0f} ± {params_df['max_depth'].std():.0f}\n",
    "  • Most common max_features: {params_df['max_features'].mode().values[0]}\n",
    "\n",
    "KEY FINDINGS:\n",
    "  • The model explains approximately {mean_r2*100:.0f}% of IMDS variance\n",
    "  • Performance is consistent across folds (low std in R²)\n",
    "  • Urban centers tend to be underpredicted (higher actual than predicted)\n",
    "  • Rural areas tend to be overpredicted (lower actual than predicted)\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When to Use Nested CV vs. Simple Train-Test Split\n",
    "\n",
    "| Scenario | Recommended Approach |\n",
    "|----------|---------------------|\n",
    "| Small dataset (< 1000 samples) | **Nested CV** - maximizes data usage |\n",
    "| Need confidence intervals | **Nested CV** - provides variance estimates |\n",
    "| Quick prototyping | Train-test split - faster iteration |\n",
    "| Very large dataset | Train-test split - nested CV is slow |\n",
    "| Final publication/report | **Nested CV** - more rigorous |\n",
    "| Comparing many models | **Nested CV** - fair comparison |\n",
    "\n",
    "---\n",
    "\n",
    "## Exercises for Students\n",
    "\n",
    "### Exercise 1: Different Fold Numbers\n",
    "Try using 10 outer folds and 3 inner folds. How does this affect the results and computation time?\n",
    "\n",
    "### Exercise 2: Stratified Splitting\n",
    "Modify the code to use `StratifiedKFold` based on binned IMDS values. Does this improve consistency?\n",
    "\n",
    "### Exercise 3: Leave-One-Out CV\n",
    "For the outer loop, implement Leave-One-Out CV (each municipality is a test set once). Compare with 5-fold.\n",
    "\n",
    "### Exercise 4: Model Comparison\n",
    "Use nested CV to compare Random Forest with Gradient Boosting. Which performs better?\n",
    "\n",
    "### Exercise 5: Feature Importance Stability\n",
    "Extract feature importances from each fold's final model. Analyze which features are consistently important.\n",
    "\n",
    "---\n",
    "\n",
    "## References\n",
    "\n",
    "- **Varma & Simon (2006)**: Bias in error estimation when using cross-validation for model selection. BMC Bioinformatics.\n",
    "- **Cawley & Talbot (2010)**: On Over-fitting in Model Selection and Subsequent Selection Bias. JMLR.\n",
    "- **Optuna Documentation**: https://optuna.readthedocs.io/\n",
    "- **DS4Bolivia Repository**: https://github.com/quarcs-lab/ds4bolivia"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
